{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c9c706f-25fa-418e-b351-87c899e9ff5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 29 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   COMBODRUGSEQ       1048575 non-null  int64  \n",
      " 1   SCREENER           1048575 non-null  object \n",
      " 2   STUDY              1048575 non-null  object \n",
      " 3   TESTDATE           1048575 non-null  object \n",
      " 4   PLATE              1048575 non-null  object \n",
      " 5   PANELNBR           1048575 non-null  int64  \n",
      " 6   CELLNBR            1048575 non-null  int64  \n",
      " 7   PREFIX1            1048575 non-null  object \n",
      " 8   NSC1               1048575 non-null  int64  \n",
      " 9   SAMPLE1            1048575 non-null  int64  \n",
      " 10  CONCINDEX1         1048575 non-null  int64  \n",
      " 11  CONC1              1048575 non-null  float64\n",
      " 12  CONCUNIT1          1048575 non-null  object \n",
      " 13  PREFIX2            1044918 non-null  object \n",
      " 14  NSC2               739881 non-null   float64\n",
      " 15  SAMPLE2            739881 non-null   float64\n",
      " 16  CONCINDEX2         1048575 non-null  int64  \n",
      " 17  CONC2              739881 non-null   float64\n",
      " 18  CONCUNIT2          1044918 non-null  object \n",
      " 19  PERCENTGROWTH      1048575 non-null  float64\n",
      " 20  PERCENTGROWTHNOTZ  1048575 non-null  float64\n",
      " 21  TESTVALUE          1048575 non-null  float64\n",
      " 22  CONTROLVALUE       1048575 non-null  float64\n",
      " 23  TZVALUE            1048575 non-null  float64\n",
      " 24  EXPECTEDGROWTH     739881 non-null   float64\n",
      " 25  SCORE              739881 non-null   float64\n",
      " 26  VALID              1048575 non-null  object \n",
      " 27  PANEL              1048575 non-null  object \n",
      " 28  CELLNAME           1048575 non-null  object \n",
      "dtypes: float64(11), int64(7), object(11)\n",
      "memory usage: 232.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Read the Growth Inhibition Data: ComboDrugGrowth_Nov2017.csv file\n",
    "\n",
    "import pandas as pd\n",
    "        \n",
    "# Path to your CSV file\n",
    "csv_file_path = \"/nfs/turbo/med-kayvan-lab/Projects/DrugCombination/b-DrugCombination/DC_Data/NCI-ALMANAC/ComboDrugGrowth_Nov2017.csv\"\n",
    "\n",
    "# Read the CSV file\n",
    "combo_druggrowth_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the data has been read correctly\n",
    "print(combo_druggrowth_df.info())\n",
    "# print(combo_druggrowth_df.head())\n",
    "# print(combo_druggrowth_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66fbca88-d903-4c23-b692-072a75e0acae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 30 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   COMBODRUGSEQ       1048575 non-null  int64  \n",
      " 1   SCREENER           1048575 non-null  object \n",
      " 2   STUDY              1048575 non-null  object \n",
      " 3   TESTDATE           1048575 non-null  object \n",
      " 4   PLATE              1048575 non-null  object \n",
      " 5   PANELNBR           1048575 non-null  int64  \n",
      " 6   CELLNBR            1048575 non-null  int64  \n",
      " 7   PREFIX1            1048575 non-null  object \n",
      " 8   NSC1               1048575 non-null  int64  \n",
      " 9   SAMPLE1            1048575 non-null  int64  \n",
      " 10  CONCINDEX1         1048575 non-null  int64  \n",
      " 11  CONC1              1048575 non-null  float64\n",
      " 12  CONCUNIT1          1048575 non-null  object \n",
      " 13  PREFIX2            1044918 non-null  object \n",
      " 14  NSC2               739881 non-null   float64\n",
      " 15  SAMPLE2            739881 non-null   float64\n",
      " 16  CONCINDEX2         1048575 non-null  int64  \n",
      " 17  CONC2              739881 non-null   float64\n",
      " 18  CONCUNIT2          1044918 non-null  object \n",
      " 19  PERCENTGROWTH      1048575 non-null  float64\n",
      " 20  PERCENTGROWTHNOTZ  1048575 non-null  float64\n",
      " 21  TESTVALUE          1048575 non-null  float64\n",
      " 22  CONTROLVALUE       1048575 non-null  float64\n",
      " 23  TZVALUE            1048575 non-null  float64\n",
      " 24  EXPECTEDGROWTH     739881 non-null   float64\n",
      " 25  SCORE              739881 non-null   float64\n",
      " 26  VALID              1048575 non-null  object \n",
      " 27  PANEL              1048575 non-null  object \n",
      " 28  CELLNAME           1048575 non-null  object \n",
      " 29  PANELACRONYM       1048575 non-null  object \n",
      "dtypes: float64(11), int64(7), object(12)\n",
      "memory usage: 240.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary mapping PANEL values to PANELACRONYM values\n",
    "panel_acronym_map = {\n",
    "    \"Breast Cancer\": \"BR\",\n",
    "    \"CNS Cancer\": \"CNS\",\n",
    "    \"Colon Cancer\": \"CO\",\n",
    "    \"Leukemia\": \"LE\",\n",
    "    \"Melanoma\": \"ME\",\n",
    "    \"Non-Small Cell Lung Cancer\": \"LC\",\n",
    "    \"Ovarian Cancer\": \"OV\",\n",
    "    \"Prostate Cancer\": \"PR\",\n",
    "    \"Renal Cancer\": \"RE\"\n",
    "}\n",
    "\n",
    "# Apply the mapping to create the PANELACRONYM column\n",
    "combo_druggrowth_df['PANELACRONYM'] = combo_druggrowth_df['PANEL'].map(panel_acronym_map)\n",
    "\n",
    "# Print or further process the combo_druggrowth_df as needed\n",
    "print(combo_druggrowth_df.info())\n",
    "# print(combo_druggrowth_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "062af68f-d184-4a85-8a9f-ee8694c52325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   COMBODRUGSEQ       1048575 non-null  int64  \n",
      " 1   SCREENER           1048575 non-null  object \n",
      " 2   STUDY              1048575 non-null  object \n",
      " 3   TESTDATE           1048575 non-null  object \n",
      " 4   PLATE              1048575 non-null  object \n",
      " 5   PANELNBR           1048575 non-null  int64  \n",
      " 6   CELLNBR            1048575 non-null  int64  \n",
      " 7   PREFIX1            1048575 non-null  object \n",
      " 8   NSC1               1048575 non-null  int64  \n",
      " 9   SAMPLE1            1048575 non-null  int64  \n",
      " 10  CONCINDEX1         1048575 non-null  int64  \n",
      " 11  CONC1              1048575 non-null  float64\n",
      " 12  CONCUNIT1          1048575 non-null  object \n",
      " 13  PREFIX2            1044918 non-null  object \n",
      " 14  NSC2               739881 non-null   float64\n",
      " 15  SAMPLE2            739881 non-null   float64\n",
      " 16  CONCINDEX2         1048575 non-null  int64  \n",
      " 17  CONC2              739881 non-null   float64\n",
      " 18  CONCUNIT2          1044918 non-null  object \n",
      " 19  PERCENTGROWTH      1048575 non-null  float64\n",
      " 20  PERCENTGROWTHNOTZ  1048575 non-null  float64\n",
      " 21  TESTVALUE          1048575 non-null  float64\n",
      " 22  CONTROLVALUE       1048575 non-null  float64\n",
      " 23  TZVALUE            1048575 non-null  float64\n",
      " 24  EXPECTEDGROWTH     739881 non-null   float64\n",
      " 25  SCORE              739881 non-null   float64\n",
      " 26  VALID              1048575 non-null  object \n",
      " 27  PANEL              1048575 non-null  object \n",
      " 28  CELLNAME           1048575 non-null  object \n",
      " 29  PANELACRONYM       1048575 non-null  object \n",
      " 30  CELLLINENAME       1048575 non-null  object \n",
      "dtypes: float64(11), int64(7), object(13)\n",
      "memory usage: 248.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Add CELLLINENAME column\n",
    "combo_druggrowth_df['CELLLINENAME'] = combo_druggrowth_df['PANELACRONYM'] + \":\" + combo_druggrowth_df['CELLNAME']\n",
    "\n",
    "# Print or further process the combo_druggrowth_df as needed\n",
    "print(combo_druggrowth_df.info())\n",
    "# print(combo_druggrowth_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5326f28-c3dc-4f18-9d4a-e42ba3279ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OV:NCI/ADR-RES        21387\n",
       "CO:KM12               21279\n",
       "ME:UACC-257           20952\n",
       "LC:NCI-H322M          20937\n",
       "RE:A498               20889\n",
       "LE:RPMI-8226          20856\n",
       "LE:K-562              20811\n",
       "CNS:SF-268            20694\n",
       "ME:LOX IMVI           20667\n",
       "CO:HCC-2998           20613\n",
       "OV:OVCAR-3            20550\n",
       "LC:NCI-H522           20391\n",
       "LC:NCI-H226           20223\n",
       "CNS:SF-539            20100\n",
       "LE:CCRF-CEM           19344\n",
       "BR:MCF7               19197\n",
       "OV:OVCAR-5            19026\n",
       "ME:SK-MEL-28          19020\n",
       "CNS:U251              18858\n",
       "ME:UACC-62            18723\n",
       "CO:HT29               18714\n",
       "PR:PC-3               18507\n",
       "BR:MDA-MB-231/ATCC    18426\n",
       "OV:IGROV1             18399\n",
       "LC:A549/ATCC          18399\n",
       "LC:NCI-H460           18399\n",
       "RE:TK-10              18399\n",
       "BR:MDA-MB-468         18363\n",
       "CO:HCT-116            18291\n",
       "BR:T-47D              18264\n",
       "CO:COLO 205           18255\n",
       "CO:SW-620             18135\n",
       "BR:BT-549             18000\n",
       "PR:DU-145             17928\n",
       "RE:RXF 393            17868\n",
       "BR:HS 578T            17826\n",
       "RE:786-0              17652\n",
       "LE:MOLT-4             17481\n",
       "OV:SK-OV-3            17454\n",
       "ME:SK-MEL-5           17337\n",
       "RE:SN12C              17049\n",
       "RE:UO-31              15708\n",
       "CNS:SNB-19            15699\n",
       "ME:MALME-3M           15618\n",
       "CNS:SNB-75            15600\n",
       "CNS:SF-295            15543\n",
       "ME:M14                15354\n",
       "RE:ACHN               15267\n",
       "LC:HOP-92             15231\n",
       "LC:NCI-H23            15222\n",
       "OV:OVCAR-4            15012\n",
       "CO:HCT-15             14892\n",
       "LC:EKVX               14805\n",
       "LE:HL-60(TB)          14388\n",
       "OV:OVCAR-8            13827\n",
       "LC:HOP-62             13332\n",
       "ME:MDA-MB-435         13098\n",
       "RE:CAKI-1             11649\n",
       "LE:SR                 10524\n",
       "ME:SK-MEL-2            4143\n",
       "Name: CELLLINENAME, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_druggrowth_df['CELLLINENAME'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "158b2ac1-3b85-4621-8caf-fa387500e706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21387 entries, 34890 to 1021043\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   COMBODRUGSEQ       21387 non-null  int64  \n",
      " 1   SCREENER           21387 non-null  object \n",
      " 2   STUDY              21387 non-null  object \n",
      " 3   TESTDATE           21387 non-null  object \n",
      " 4   PLATE              21387 non-null  object \n",
      " 5   PANELNBR           21387 non-null  int64  \n",
      " 6   CELLNBR            21387 non-null  int64  \n",
      " 7   PREFIX1            21387 non-null  object \n",
      " 8   NSC1               21387 non-null  int64  \n",
      " 9   SAMPLE1            21387 non-null  int64  \n",
      " 10  CONCINDEX1         21387 non-null  int64  \n",
      " 11  CONC1              21387 non-null  float64\n",
      " 12  CONCUNIT1          21387 non-null  object \n",
      " 13  PREFIX2            21327 non-null  object \n",
      " 14  NSC2               15030 non-null  float64\n",
      " 15  SAMPLE2            15030 non-null  float64\n",
      " 16  CONCINDEX2         21387 non-null  int64  \n",
      " 17  CONC2              15030 non-null  float64\n",
      " 18  CONCUNIT2          21327 non-null  object \n",
      " 19  PERCENTGROWTH      21387 non-null  float64\n",
      " 20  PERCENTGROWTHNOTZ  21387 non-null  float64\n",
      " 21  TESTVALUE          21387 non-null  float64\n",
      " 22  CONTROLVALUE       21387 non-null  float64\n",
      " 23  TZVALUE            21387 non-null  float64\n",
      " 24  EXPECTEDGROWTH     15030 non-null  float64\n",
      " 25  SCORE              15030 non-null  float64\n",
      " 26  VALID              21387 non-null  object \n",
      " 27  PANEL              21387 non-null  object \n",
      " 28  CELLNAME           21387 non-null  object \n",
      " 29  PANELACRONYM       21387 non-null  object \n",
      " 30  CELLLINENAME       21387 non-null  object \n",
      "dtypes: float64(11), int64(7), object(13)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Make a subset df for \"OV:NCI/ADR-RES\" cell line:\n",
    "\n",
    "df_OV_NCI_ADR_RES = combo_druggrowth_df[combo_druggrowth_df['CELLLINENAME'] == \"OV:NCI/ADR-RES\"]\n",
    "df_OV_NCI_ADR_RES.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb2f0f9b-cf33-4972-926e-da427bb69f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_OV_NCI_ADR_RES['NSC1'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e293aeb8-2536-40b9-b0e6-19814c75213e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_OV_NCI_ADR_RES['NSC2'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39264b25-5b8c-4447-b52d-66c154d7727b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_OV_NCI_ADR_RES['CONC1'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2f88b90-5e71-4f4c-aa87-e88f18669248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_OV_NCI_ADR_RES['CONC2'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc33ec65-6b13-4c05-b9c9-65da67a07396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21387 entries, 34890 to 1021043\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   COMBODRUGSEQ       21387 non-null  int64  \n",
      " 1   SCREENER           21387 non-null  object \n",
      " 2   STUDY              21387 non-null  object \n",
      " 3   TESTDATE           21387 non-null  object \n",
      " 4   PLATE              21387 non-null  object \n",
      " 5   PANELNBR           21387 non-null  int64  \n",
      " 6   CELLNBR            21387 non-null  int64  \n",
      " 7   PREFIX1            21387 non-null  object \n",
      " 8   NSC1               21387 non-null  int64  \n",
      " 9   SAMPLE1            21387 non-null  int64  \n",
      " 10  CONCINDEX1         21387 non-null  int64  \n",
      " 11  CONC1              21387 non-null  float64\n",
      " 12  CONCUNIT1          21387 non-null  object \n",
      " 13  PREFIX2            21327 non-null  object \n",
      " 14  NSC2               15030 non-null  float64\n",
      " 15  SAMPLE2            15030 non-null  float64\n",
      " 16  CONCINDEX2         21387 non-null  int64  \n",
      " 17  CONC2              15030 non-null  float64\n",
      " 18  CONCUNIT2          21327 non-null  object \n",
      " 19  PERCENTGROWTH      21387 non-null  float64\n",
      " 20  PERCENTGROWTHNOTZ  21387 non-null  float64\n",
      " 21  TESTVALUE          21387 non-null  float64\n",
      " 22  CONTROLVALUE       21387 non-null  float64\n",
      " 23  TZVALUE            21387 non-null  float64\n",
      " 24  EXPECTEDGROWTH     15030 non-null  float64\n",
      " 25  SCORE              15030 non-null  float64\n",
      " 26  VALID              21387 non-null  object \n",
      " 27  PANEL              21387 non-null  object \n",
      " 28  CELLNAME           21387 non-null  object \n",
      " 29  PANELACRONYM       21387 non-null  object \n",
      " 30  CELLLINENAME       21387 non-null  object \n",
      "dtypes: float64(11), int64(7), object(13)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data = df_OV_NCI_ADR_RES\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d807dbb3-496c-49c8-ab8a-a01f29d903a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15030 entries, 34890 to 1021025\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   COMBODRUGSEQ       15030 non-null  int64  \n",
      " 1   SCREENER           15030 non-null  object \n",
      " 2   STUDY              15030 non-null  object \n",
      " 3   TESTDATE           15030 non-null  object \n",
      " 4   PLATE              15030 non-null  object \n",
      " 5   PANELNBR           15030 non-null  int64  \n",
      " 6   CELLNBR            15030 non-null  int64  \n",
      " 7   PREFIX1            15030 non-null  object \n",
      " 8   NSC1               15030 non-null  int64  \n",
      " 9   SAMPLE1            15030 non-null  int64  \n",
      " 10  CONCINDEX1         15030 non-null  int64  \n",
      " 11  CONC1              15030 non-null  float64\n",
      " 12  CONCUNIT1          15030 non-null  object \n",
      " 13  PREFIX2            15030 non-null  object \n",
      " 14  NSC2               15030 non-null  float64\n",
      " 15  SAMPLE2            15030 non-null  float64\n",
      " 16  CONCINDEX2         15030 non-null  int64  \n",
      " 17  CONC2              15030 non-null  float64\n",
      " 18  CONCUNIT2          15030 non-null  object \n",
      " 19  PERCENTGROWTH      15030 non-null  float64\n",
      " 20  PERCENTGROWTHNOTZ  15030 non-null  float64\n",
      " 21  TESTVALUE          15030 non-null  float64\n",
      " 22  CONTROLVALUE       15030 non-null  float64\n",
      " 23  TZVALUE            15030 non-null  float64\n",
      " 24  EXPECTEDGROWTH     15030 non-null  float64\n",
      " 25  SCORE              15030 non-null  float64\n",
      " 26  VALID              15030 non-null  object \n",
      " 27  PANEL              15030 non-null  object \n",
      " 28  CELLNAME           15030 non-null  object \n",
      " 29  PANELACRONYM       15030 non-null  object \n",
      " 30  CELLLINENAME       15030 non-null  object \n",
      "dtypes: float64(11), int64(7), object(13)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Drop na values\n",
    "data = data.dropna()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b813e81-e2a0-4b7d-a333-051c2c9f8df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec2b57ad-d22a-4c3e-952d-bc19fd3e6609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC on test set: 0.33205610179294387\n",
      "Standard Deviation of AUC on test set: 0.041314577940275904\n",
      "AUCs on validation set for each fold: [0.40699187363038714, 0.4161662452591656, 0.3470304802122246, 0.3340589806107047, 0.30473181690536366]\n"
     ]
    }
   ],
   "source": [
    "# FNN classification model with 5-fold cross validations (PyTorch)\n",
    "## (Code for individual sample)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "\n",
    "# Suppress the specific UserWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Custom function to transform y\n",
    "def transform_labels(y):\n",
    "    return torch.tensor(np.where(y <= 0, 0, 1), dtype=torch.float32)\n",
    "\n",
    "# Preprocess the data\n",
    "X = data[['NSC1', 'NSC2', 'CONC1', 'CONC2']].values\n",
    "y = data['PERCENTGROWTH'].values\n",
    "\n",
    "# Transform labels\n",
    "y = transform_labels(y)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define your FNN model\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Initialize KFold for validation within the training set\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize variables for storing results\n",
    "auc_per_fold = []\n",
    "auc_test_per_fold = []\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Loop through the folds\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    # Standardize the input features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "    X_val_scaled = scaler.transform(X_val_fold)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Convert numpy arrays to PyTorch tensors and move to GPU\n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train_fold, dtype=torch.float32).to(device)\n",
    "    X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32).to(device)\n",
    "    y_val_tensor = torch.tensor(y_val_fold, dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Create the model and move to GPU\n",
    "    model = FNN(input_size=X_train.shape[1]).to(device)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(50):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validate the model on the validation set\n",
    "    with torch.no_grad():\n",
    "        y_val_pred_prob = model(X_val_tensor).cpu().numpy()\n",
    "\n",
    "    # Calculate AUC on validation set\n",
    "    auc_valid = roc_auc_score(y_val_fold, y_val_pred_prob)\n",
    "    auc_per_fold.append(auc_valid)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    with torch.no_grad():\n",
    "        y_test_pred_prob = model(X_test_tensor).cpu().numpy()\n",
    "\n",
    "    # Calculate AUC on test set\n",
    "    auc_test = roc_auc_score(y_test, y_test_pred_prob)\n",
    "    auc_test_per_fold.append(auc_test)\n",
    "\n",
    "# Calculate mean and standard deviation of AUC scores\n",
    "mean_auc = np.mean(auc_test_per_fold)\n",
    "std_auc = np.std(auc_test_per_fold)\n",
    "\n",
    "print(f'Mean AUC on test set: {mean_auc}')\n",
    "print(f'Standard Deviation of AUC on test set: {std_auc}')\n",
    "print(f'AUCs on validation set for each fold: {auc_per_fold}')\n",
    "\n",
    "# Reset the warnings filter to default behavior\n",
    "warnings.resetwarnings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81952719-5c46-4cdc-b28e-4b6e2adcbeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNN classification model with 5-fold cross validations (PyTorch)\n",
    "## (Code for all)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "\n",
    "# Suppress the specific UserWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Custom function to transform y\n",
    "def transform_labels(y):\n",
    "    return torch.tensor(np.where(y <= 0, 0, 1), dtype=torch.float32)\n",
    "\n",
    "# Define your FNN model\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each cell line\n",
    "for cell_line in combo_druggrowth_df['CELLLINENAME'].unique():\n",
    "    # Extract subset for the current cell line\n",
    "    subset = combo_druggrowth_df[combo_druggrowth_df['CELLLINENAME'] == cell_line]   \n",
    "    # Drop na values\n",
    "    subset = subset.dropna()   \n",
    "    # Extract features and target\n",
    "    X = subset[['NSC1', 'NSC2', 'CONC1', 'CONC2']].values\n",
    "    y = subset['PERCENTGROWTH'].values   \n",
    "    # Transform labels\n",
    "    y = transform_labels(y)\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    # Initialize lists to store AUC scores for each fold\n",
    "    auc_test_per_fold = []\n",
    "    # Loop through the folds\n",
    "    for train_index, valid_index in kf.split(X_train):\n",
    "        X_train_fold, X_valid_fold = X_train[train_index], X_train[valid_index]\n",
    "        y_train_fold, y_valid_fold = y_train[train_index], y_train[valid_index]\n",
    "        # Standardize the input features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_valid_fold_scaled = scaler.transform(X_valid_fold)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        # Convert numpy arrays to PyTorch tensors and move to GPU if available\n",
    "        X_train_tensor = torch.tensor(X_train_fold_scaled, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train_fold, dtype=torch.float32)\n",
    "        X_valid_tensor = torch.tensor(X_valid_fold_scaled, dtype=torch.float32)\n",
    "        y_valid_tensor = torch.tensor(y_valid_fold, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "        # Check if CUDA is available and move tensors to GPU\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        X_train_tensor, y_train_tensor = X_train_tensor.to(device), y_train_tensor.to(device)\n",
    "        X_valid_tensor, y_valid_tensor = X_valid_tensor.to(device), y_valid_tensor.to(device)\n",
    "        X_test_tensor = X_test_tensor.to(device)\n",
    "        # Create the model and move to GPU\n",
    "        model = FNN(input_size=X_train.shape[1]).to(device)\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters())\n",
    "        # Train the model\n",
    "        for epoch in range(50):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train_tensor)\n",
    "            loss = criterion(outputs, y_train_tensor.view(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # Evaluate the model on the test set\n",
    "        with torch.no_grad():\n",
    "            predictions_test = model(X_test_tensor).cpu().numpy()\n",
    "        # Calculate AUC on test set\n",
    "        auc_test = roc_auc_score(y_test, predictions_test)\n",
    "        auc_test_per_fold.append(auc_test)\n",
    "    # Calculate mean and standard deviation of AUC scores\n",
    "    mean_auc = np.mean(auc_test_per_fold)\n",
    "    std_auc = np.std(auc_test_per_fold)\n",
    "    # Store results in a dictionary\n",
    "    result = {'CellLine': cell_line,\n",
    "              'Mean_AUC': mean_auc,\n",
    "              'Std_AUC': std_auc}    \n",
    "    # Append result to the list\n",
    "    results.append(result)\n",
    "\n",
    "# Convert list of dictionaries to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to a CSV file\n",
    "results_df.to_csv('auc_results_PyTorch.csv', index=False)\n",
    "\n",
    "# Reset the warnings filter to default behavior\n",
    "warnings.resetwarnings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dc34fca-8a90-427b-8dbb-c4e72c174825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "results_df = pd.read_csv('auc_results_PyTorch.csv')\n",
    "\n",
    "# Round the 'Mean_RMSE' and 'Std_RMSE' columns to two decimals\n",
    "results_df['Mean_AUC'] = results_df['Mean_AUC'].round(2)\n",
    "results_df['Std_AUC'] = results_df['Std_AUC'].round(4)\n",
    "\n",
    "results_df.to_csv('rounded_auc_results_PyTorch.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8475efd9-45e3-4a6b-a87b-0b6e2345335a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE on test set: 85.47429649071134\n",
      "Standard Deviation of RMSE on test set: 0.4128364604278218\n",
      "RMSEs on validation set for each fold: [85.05968550747204, 85.7843063630541, 85.73536009956194, 84.26001384023628, 85.79421355647237]\n"
     ]
    }
   ],
   "source": [
    "# FNN regression model with 5-fold cross validations (PyTorch)\n",
    "## (Code for individual sample)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "\n",
    "# Suppress the specific UserWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Preprocess the data\n",
    "X = data[['NSC1', 'NSC2', 'CONC1', 'CONC2']].values\n",
    "y = data['PERCENTGROWTH'].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define your FNN model\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define a function to build and evaluate the model\n",
    "def build_and_evaluate_model(X_train_fold, X_valid_fold, y_train_fold, y_valid_fold, X_test, y_test):\n",
    "    # Create the model\n",
    "    model = FNN(input_size=X_train_fold.shape[1])\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    # Train the model\n",
    "    for epoch in range(50):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(torch.tensor(X_train_fold, dtype=torch.float32))\n",
    "        loss = criterion(outputs, torch.tensor(y_train_fold, dtype=torch.float32).view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Evaluate the model on the validation set\n",
    "    with torch.no_grad():\n",
    "        predictions_valid = model(torch.tensor(X_valid_fold, dtype=torch.float32)).numpy()\n",
    "        rmse_valid = np.sqrt(mean_squared_error(y_valid_fold, predictions_valid))\n",
    "    # Evaluate the model on the test set\n",
    "    with torch.no_grad():\n",
    "        predictions_test = model(torch.tensor(X_test, dtype=torch.float32)).numpy()\n",
    "        rmse_test = np.sqrt(mean_squared_error(y_test, predictions_test))\n",
    "    return rmse_valid, rmse_test\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store RMSE scores for each fold\n",
    "rmse_per_fold = []\n",
    "rmse_test_per_fold = []\n",
    "\n",
    "# Loop through the folds\n",
    "for train_index, valid_index in kf.split(X_train):\n",
    "    X_train_fold, X_valid_fold = X_train[train_index], X_train[valid_index]\n",
    "    y_train_fold, y_valid_fold = y_train[train_index], y_train[valid_index]\n",
    "    # Standardize the input features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "    X_valid_fold_scaled = scaler.transform(X_valid_fold)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    # Evaluate the model for the current fold\n",
    "    rmse_valid, rmse_test = build_and_evaluate_model(X_train_fold_scaled, X_valid_fold_scaled, y_train_fold, y_valid_fold, X_test_scaled, y_test)\n",
    "    rmse_per_fold.append(rmse_valid)\n",
    "    rmse_test_per_fold.append(rmse_test)\n",
    "\n",
    "# Calculate mean and standard deviation of RMSE scores\n",
    "mean_rmse = np.mean(rmse_test_per_fold)\n",
    "std_rmse = np.std(rmse_test_per_fold)\n",
    "\n",
    "print(f'Mean RMSE on test set: {mean_rmse}')\n",
    "print(f'Standard Deviation of RMSE on test set: {std_rmse}')\n",
    "print(f'RMSEs on validation set for each fold: {rmse_per_fold}')\n",
    "\n",
    "# Reset the warnings filter to default behavior\n",
    "warnings.resetwarnings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c72e783a-0a72-409c-b016-8ee98fa2d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNN regression model with 5-fold cross validations (PyTorch)\n",
    "## (Code for all)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "\n",
    "# Suppress the specific UserWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Define your FNN model\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Function to preprocess data, train the model, and evaluate\n",
    "def preprocess_train_evaluate(X_train_fold, X_valid_fold, y_train_fold, y_valid_fold, X_test, y_test):\n",
    "    # Create the model\n",
    "    model = FNN(input_size=X_train_fold.shape[1])\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    # Train the model\n",
    "    for epoch in range(50):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(torch.tensor(X_train_fold, dtype=torch.float32))\n",
    "        loss = criterion(outputs, torch.tensor(y_train_fold, dtype=torch.float32).view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Evaluate the model on the validation set\n",
    "    with torch.no_grad():\n",
    "        predictions_valid = model(torch.tensor(X_valid_fold, dtype=torch.float32)).numpy()\n",
    "        rmse_valid = np.sqrt(mean_squared_error(y_valid_fold, predictions_valid))\n",
    "    # Evaluate the model on the test set\n",
    "    with torch.no_grad():\n",
    "        predictions_test = model(torch.tensor(X_test, dtype=torch.float32)).numpy()\n",
    "        rmse_test = np.sqrt(mean_squared_error(y_test, predictions_test))\n",
    "    return rmse_valid, rmse_test\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each cell line\n",
    "for cell_line in combo_druggrowth_df['CELLLINENAME'].unique():\n",
    "    # Extract subset for the current cell line\n",
    "    subset = combo_druggrowth_df[combo_druggrowth_df['CELLLINENAME'] == cell_line]    \n",
    "    # Drop na values\n",
    "    subset = subset.dropna()    \n",
    "    # Extract features and target\n",
    "    X = subset[['NSC1', 'NSC2', 'CONC1', 'CONC2']].values\n",
    "    y = subset['PERCENTGROWTH'].values  \n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    # Initialize lists to store RMSE scores for each fold\n",
    "    rmse_per_fold = []\n",
    "    rmse_test_per_fold = []\n",
    "    # Loop through the folds\n",
    "    for train_index, valid_index in kf.split(X_train):\n",
    "        X_train_fold, X_valid_fold = X_train[train_index], X_train[valid_index]\n",
    "        y_train_fold, y_valid_fold = y_train[train_index], y_train[valid_index]\n",
    "        # Standardize the input features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_valid_fold_scaled = scaler.transform(X_valid_fold)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        # Evaluate the model for the current fold\n",
    "        rmse_valid, rmse_test = preprocess_train_evaluate(X_train_fold_scaled, X_valid_fold_scaled, y_train_fold, y_valid_fold, X_test_scaled, y_test)\n",
    "        rmse_per_fold.append(rmse_valid)\n",
    "        rmse_test_per_fold.append(rmse_test)\n",
    "    # Calculate mean and standard deviation of RMSE scores\n",
    "    mean_rmse = np.mean(rmse_test_per_fold)\n",
    "    std_rmse = np.std(rmse_test_per_fold)\n",
    "    # Store results in a dictionary\n",
    "    result = {'CellLine': cell_line,\n",
    "              'Mean_RMSE': mean_rmse,\n",
    "              'Std_RMSE': std_rmse}   \n",
    "    # Append result to the list\n",
    "    results.append(result)\n",
    "\n",
    "# Convert list of dictionaries to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to a CSV file\n",
    "results_df.to_csv('rmse_results_PyTorch.csv', index=False)\n",
    "\n",
    "# Reset the warnings filter to default behavior\n",
    "warnings.resetwarnings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97568626-565d-45f9-8ffb-047dcab55e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "results_df = pd.read_csv('rmse_results_PyTorch.csv')\n",
    "\n",
    "# Round the 'Mean_RMSE' and 'Std_RMSE' columns to two decimals\n",
    "results_df['Mean_RMSE'] = results_df['Mean_RMSE'].round(2)\n",
    "results_df['Std_RMSE'] = results_df['Std_RMSE'].round(4)\n",
    "\n",
    "results_df.to_csv('rounded_rmse_results_PyTorch.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9910fb-8c8c-44bf-b4d0-392e673884f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
