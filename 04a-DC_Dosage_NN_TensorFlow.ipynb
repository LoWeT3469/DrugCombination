{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c9c706f-25fa-418e-b351-87c899e9ff5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 29 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   COMBODRUGSEQ       1048575 non-null  int64  \n",
      " 1   SCREENER           1048575 non-null  object \n",
      " 2   STUDY              1048575 non-null  object \n",
      " 3   TESTDATE           1048575 non-null  object \n",
      " 4   PLATE              1048575 non-null  object \n",
      " 5   PANELNBR           1048575 non-null  int64  \n",
      " 6   CELLNBR            1048575 non-null  int64  \n",
      " 7   PREFIX1            1048575 non-null  object \n",
      " 8   NSC1               1048575 non-null  int64  \n",
      " 9   SAMPLE1            1048575 non-null  int64  \n",
      " 10  CONCINDEX1         1048575 non-null  int64  \n",
      " 11  CONC1              1048575 non-null  float64\n",
      " 12  CONCUNIT1          1048575 non-null  object \n",
      " 13  PREFIX2            1044918 non-null  object \n",
      " 14  NSC2               739881 non-null   float64\n",
      " 15  SAMPLE2            739881 non-null   float64\n",
      " 16  CONCINDEX2         1048575 non-null  int64  \n",
      " 17  CONC2              739881 non-null   float64\n",
      " 18  CONCUNIT2          1044918 non-null  object \n",
      " 19  PERCENTGROWTH      1048575 non-null  float64\n",
      " 20  PERCENTGROWTHNOTZ  1048575 non-null  float64\n",
      " 21  TESTVALUE          1048575 non-null  float64\n",
      " 22  CONTROLVALUE       1048575 non-null  float64\n",
      " 23  TZVALUE            1048575 non-null  float64\n",
      " 24  EXPECTEDGROWTH     739881 non-null   float64\n",
      " 25  SCORE              739881 non-null   float64\n",
      " 26  VALID              1048575 non-null  object \n",
      " 27  PANEL              1048575 non-null  object \n",
      " 28  CELLNAME           1048575 non-null  object \n",
      "dtypes: float64(11), int64(7), object(11)\n",
      "memory usage: 232.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Read the Growth Inhibition Data: ComboDrugGrowth_Nov2017.csv file\n",
    "import pandas as pd\n",
    "        \n",
    "# Path to your CSV file\n",
    "csv_file_path = \"/nfs/turbo/med-kayvan-lab/Projects/DrugCombination/b-DrugCombination/DC_Data/NCI-ALMANAC/ComboDrugGrowth_Nov2017.csv\"\n",
    "\n",
    "# Read the CSV file\n",
    "combo_druggrowth_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the data has been read correctly\n",
    "print(combo_druggrowth_df.info())\n",
    "# print(combo_druggrowth_df.head())\n",
    "# print(combo_druggrowth_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66fbca88-d903-4c23-b692-072a75e0acae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 30 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   COMBODRUGSEQ       1048575 non-null  int64  \n",
      " 1   SCREENER           1048575 non-null  object \n",
      " 2   STUDY              1048575 non-null  object \n",
      " 3   TESTDATE           1048575 non-null  object \n",
      " 4   PLATE              1048575 non-null  object \n",
      " 5   PANELNBR           1048575 non-null  int64  \n",
      " 6   CELLNBR            1048575 non-null  int64  \n",
      " 7   PREFIX1            1048575 non-null  object \n",
      " 8   NSC1               1048575 non-null  int64  \n",
      " 9   SAMPLE1            1048575 non-null  int64  \n",
      " 10  CONCINDEX1         1048575 non-null  int64  \n",
      " 11  CONC1              1048575 non-null  float64\n",
      " 12  CONCUNIT1          1048575 non-null  object \n",
      " 13  PREFIX2            1044918 non-null  object \n",
      " 14  NSC2               739881 non-null   float64\n",
      " 15  SAMPLE2            739881 non-null   float64\n",
      " 16  CONCINDEX2         1048575 non-null  int64  \n",
      " 17  CONC2              739881 non-null   float64\n",
      " 18  CONCUNIT2          1044918 non-null  object \n",
      " 19  PERCENTGROWTH      1048575 non-null  float64\n",
      " 20  PERCENTGROWTHNOTZ  1048575 non-null  float64\n",
      " 21  TESTVALUE          1048575 non-null  float64\n",
      " 22  CONTROLVALUE       1048575 non-null  float64\n",
      " 23  TZVALUE            1048575 non-null  float64\n",
      " 24  EXPECTEDGROWTH     739881 non-null   float64\n",
      " 25  SCORE              739881 non-null   float64\n",
      " 26  VALID              1048575 non-null  object \n",
      " 27  PANEL              1048575 non-null  object \n",
      " 28  CELLNAME           1048575 non-null  object \n",
      " 29  PANELACRONYM       1048575 non-null  object \n",
      "dtypes: float64(11), int64(7), object(12)\n",
      "memory usage: 240.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary mapping PANEL values to PANELACRONYM values\n",
    "panel_acronym_map = {\n",
    "    \"Breast Cancer\": \"BR\",\n",
    "    \"CNS Cancer\": \"CNS\",\n",
    "    \"Colon Cancer\": \"CO\",\n",
    "    \"Leukemia\": \"LE\",\n",
    "    \"Melanoma\": \"ME\",\n",
    "    \"Non-Small Cell Lung Cancer\": \"LC\",\n",
    "    \"Ovarian Cancer\": \"OV\",\n",
    "    \"Prostate Cancer\": \"PR\",\n",
    "    \"Renal Cancer\": \"RE\"\n",
    "}\n",
    "\n",
    "# Apply the mapping to create the PANELACRONYM column\n",
    "combo_druggrowth_df['PANELACRONYM'] = combo_druggrowth_df['PANEL'].map(panel_acronym_map)\n",
    "\n",
    "# Print or further process the combo_druggrowth_df as needed\n",
    "print(combo_druggrowth_df.info())\n",
    "# print(combo_druggrowth_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "062af68f-d184-4a85-8a9f-ee8694c52325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   COMBODRUGSEQ       1048575 non-null  int64  \n",
      " 1   SCREENER           1048575 non-null  object \n",
      " 2   STUDY              1048575 non-null  object \n",
      " 3   TESTDATE           1048575 non-null  object \n",
      " 4   PLATE              1048575 non-null  object \n",
      " 5   PANELNBR           1048575 non-null  int64  \n",
      " 6   CELLNBR            1048575 non-null  int64  \n",
      " 7   PREFIX1            1048575 non-null  object \n",
      " 8   NSC1               1048575 non-null  int64  \n",
      " 9   SAMPLE1            1048575 non-null  int64  \n",
      " 10  CONCINDEX1         1048575 non-null  int64  \n",
      " 11  CONC1              1048575 non-null  float64\n",
      " 12  CONCUNIT1          1048575 non-null  object \n",
      " 13  PREFIX2            1044918 non-null  object \n",
      " 14  NSC2               739881 non-null   float64\n",
      " 15  SAMPLE2            739881 non-null   float64\n",
      " 16  CONCINDEX2         1048575 non-null  int64  \n",
      " 17  CONC2              739881 non-null   float64\n",
      " 18  CONCUNIT2          1044918 non-null  object \n",
      " 19  PERCENTGROWTH      1048575 non-null  float64\n",
      " 20  PERCENTGROWTHNOTZ  1048575 non-null  float64\n",
      " 21  TESTVALUE          1048575 non-null  float64\n",
      " 22  CONTROLVALUE       1048575 non-null  float64\n",
      " 23  TZVALUE            1048575 non-null  float64\n",
      " 24  EXPECTEDGROWTH     739881 non-null   float64\n",
      " 25  SCORE              739881 non-null   float64\n",
      " 26  VALID              1048575 non-null  object \n",
      " 27  PANEL              1048575 non-null  object \n",
      " 28  CELLNAME           1048575 non-null  object \n",
      " 29  PANELACRONYM       1048575 non-null  object \n",
      " 30  CELLLINENAME       1048575 non-null  object \n",
      "dtypes: float64(11), int64(7), object(13)\n",
      "memory usage: 248.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Add CELLLINENAME column\n",
    "combo_druggrowth_df['CELLLINENAME'] = combo_druggrowth_df['PANELACRONYM'] + \":\" + combo_druggrowth_df['CELLNAME']\n",
    "\n",
    "# Print or further process the combo_druggrowth_df as needed\n",
    "print(combo_druggrowth_df.info())\n",
    "# print(combo_druggrowth_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5326f28-c3dc-4f18-9d4a-e42ba3279ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OV:NCI/ADR-RES        21387\n",
       "CO:KM12               21279\n",
       "ME:UACC-257           20952\n",
       "LC:NCI-H322M          20937\n",
       "RE:A498               20889\n",
       "LE:RPMI-8226          20856\n",
       "LE:K-562              20811\n",
       "CNS:SF-268            20694\n",
       "ME:LOX IMVI           20667\n",
       "CO:HCC-2998           20613\n",
       "OV:OVCAR-3            20550\n",
       "LC:NCI-H522           20391\n",
       "LC:NCI-H226           20223\n",
       "CNS:SF-539            20100\n",
       "LE:CCRF-CEM           19344\n",
       "BR:MCF7               19197\n",
       "OV:OVCAR-5            19026\n",
       "ME:SK-MEL-28          19020\n",
       "CNS:U251              18858\n",
       "ME:UACC-62            18723\n",
       "CO:HT29               18714\n",
       "PR:PC-3               18507\n",
       "BR:MDA-MB-231/ATCC    18426\n",
       "OV:IGROV1             18399\n",
       "LC:A549/ATCC          18399\n",
       "LC:NCI-H460           18399\n",
       "RE:TK-10              18399\n",
       "BR:MDA-MB-468         18363\n",
       "CO:HCT-116            18291\n",
       "BR:T-47D              18264\n",
       "CO:COLO 205           18255\n",
       "CO:SW-620             18135\n",
       "BR:BT-549             18000\n",
       "PR:DU-145             17928\n",
       "RE:RXF 393            17868\n",
       "BR:HS 578T            17826\n",
       "RE:786-0              17652\n",
       "LE:MOLT-4             17481\n",
       "OV:SK-OV-3            17454\n",
       "ME:SK-MEL-5           17337\n",
       "RE:SN12C              17049\n",
       "RE:UO-31              15708\n",
       "CNS:SNB-19            15699\n",
       "ME:MALME-3M           15618\n",
       "CNS:SNB-75            15600\n",
       "CNS:SF-295            15543\n",
       "ME:M14                15354\n",
       "RE:ACHN               15267\n",
       "LC:HOP-92             15231\n",
       "LC:NCI-H23            15222\n",
       "OV:OVCAR-4            15012\n",
       "CO:HCT-15             14892\n",
       "LC:EKVX               14805\n",
       "LE:HL-60(TB)          14388\n",
       "OV:OVCAR-8            13827\n",
       "LC:HOP-62             13332\n",
       "ME:MDA-MB-435         13098\n",
       "RE:CAKI-1             11649\n",
       "LE:SR                 10524\n",
       "ME:SK-MEL-2            4143\n",
       "Name: CELLLINENAME, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_druggrowth_df['CELLLINENAME'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "158b2ac1-3b85-4621-8caf-fa387500e706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21387 entries, 34890 to 1021043\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   COMBODRUGSEQ       21387 non-null  int64  \n",
      " 1   SCREENER           21387 non-null  object \n",
      " 2   STUDY              21387 non-null  object \n",
      " 3   TESTDATE           21387 non-null  object \n",
      " 4   PLATE              21387 non-null  object \n",
      " 5   PANELNBR           21387 non-null  int64  \n",
      " 6   CELLNBR            21387 non-null  int64  \n",
      " 7   PREFIX1            21387 non-null  object \n",
      " 8   NSC1               21387 non-null  int64  \n",
      " 9   SAMPLE1            21387 non-null  int64  \n",
      " 10  CONCINDEX1         21387 non-null  int64  \n",
      " 11  CONC1              21387 non-null  float64\n",
      " 12  CONCUNIT1          21387 non-null  object \n",
      " 13  PREFIX2            21327 non-null  object \n",
      " 14  NSC2               15030 non-null  float64\n",
      " 15  SAMPLE2            15030 non-null  float64\n",
      " 16  CONCINDEX2         21387 non-null  int64  \n",
      " 17  CONC2              15030 non-null  float64\n",
      " 18  CONCUNIT2          21327 non-null  object \n",
      " 19  PERCENTGROWTH      21387 non-null  float64\n",
      " 20  PERCENTGROWTHNOTZ  21387 non-null  float64\n",
      " 21  TESTVALUE          21387 non-null  float64\n",
      " 22  CONTROLVALUE       21387 non-null  float64\n",
      " 23  TZVALUE            21387 non-null  float64\n",
      " 24  EXPECTEDGROWTH     15030 non-null  float64\n",
      " 25  SCORE              15030 non-null  float64\n",
      " 26  VALID              21387 non-null  object \n",
      " 27  PANEL              21387 non-null  object \n",
      " 28  CELLNAME           21387 non-null  object \n",
      " 29  PANELACRONYM       21387 non-null  object \n",
      " 30  CELLLINENAME       21387 non-null  object \n",
      "dtypes: float64(11), int64(7), object(13)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Make a subset df for \"OV:NCI/ADR-RES\" cell line:\n",
    "df_OV_NCI_ADR_RES = combo_druggrowth_df[combo_druggrowth_df['CELLLINENAME'] == \"OV:NCI/ADR-RES\"]\n",
    "df_OV_NCI_ADR_RES.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb2f0f9b-cf33-4972-926e-da427bb69f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_OV_NCI_ADR_RES['NSC1'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e293aeb8-2536-40b9-b0e6-19814c75213e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_OV_NCI_ADR_RES['NSC2'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39264b25-5b8c-4447-b52d-66c154d7727b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_OV_NCI_ADR_RES['CONC1'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2f88b90-5e71-4f4c-aa87-e88f18669248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_OV_NCI_ADR_RES['CONC2'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc33ec65-6b13-4c05-b9c9-65da67a07396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21387 entries, 34890 to 1021043\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   COMBODRUGSEQ       21387 non-null  int64  \n",
      " 1   SCREENER           21387 non-null  object \n",
      " 2   STUDY              21387 non-null  object \n",
      " 3   TESTDATE           21387 non-null  object \n",
      " 4   PLATE              21387 non-null  object \n",
      " 5   PANELNBR           21387 non-null  int64  \n",
      " 6   CELLNBR            21387 non-null  int64  \n",
      " 7   PREFIX1            21387 non-null  object \n",
      " 8   NSC1               21387 non-null  int64  \n",
      " 9   SAMPLE1            21387 non-null  int64  \n",
      " 10  CONCINDEX1         21387 non-null  int64  \n",
      " 11  CONC1              21387 non-null  float64\n",
      " 12  CONCUNIT1          21387 non-null  object \n",
      " 13  PREFIX2            21327 non-null  object \n",
      " 14  NSC2               15030 non-null  float64\n",
      " 15  SAMPLE2            15030 non-null  float64\n",
      " 16  CONCINDEX2         21387 non-null  int64  \n",
      " 17  CONC2              15030 non-null  float64\n",
      " 18  CONCUNIT2          21327 non-null  object \n",
      " 19  PERCENTGROWTH      21387 non-null  float64\n",
      " 20  PERCENTGROWTHNOTZ  21387 non-null  float64\n",
      " 21  TESTVALUE          21387 non-null  float64\n",
      " 22  CONTROLVALUE       21387 non-null  float64\n",
      " 23  TZVALUE            21387 non-null  float64\n",
      " 24  EXPECTEDGROWTH     15030 non-null  float64\n",
      " 25  SCORE              15030 non-null  float64\n",
      " 26  VALID              21387 non-null  object \n",
      " 27  PANEL              21387 non-null  object \n",
      " 28  CELLNAME           21387 non-null  object \n",
      " 29  PANELACRONYM       21387 non-null  object \n",
      " 30  CELLLINENAME       21387 non-null  object \n",
      "dtypes: float64(11), int64(7), object(13)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data = df_OV_NCI_ADR_RES\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d807dbb3-496c-49c8-ab8a-a01f29d903a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15030 entries, 34890 to 1021025\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   COMBODRUGSEQ       15030 non-null  int64  \n",
      " 1   SCREENER           15030 non-null  object \n",
      " 2   STUDY              15030 non-null  object \n",
      " 3   TESTDATE           15030 non-null  object \n",
      " 4   PLATE              15030 non-null  object \n",
      " 5   PANELNBR           15030 non-null  int64  \n",
      " 6   CELLNBR            15030 non-null  int64  \n",
      " 7   PREFIX1            15030 non-null  object \n",
      " 8   NSC1               15030 non-null  int64  \n",
      " 9   SAMPLE1            15030 non-null  int64  \n",
      " 10  CONCINDEX1         15030 non-null  int64  \n",
      " 11  CONC1              15030 non-null  float64\n",
      " 12  CONCUNIT1          15030 non-null  object \n",
      " 13  PREFIX2            15030 non-null  object \n",
      " 14  NSC2               15030 non-null  float64\n",
      " 15  SAMPLE2            15030 non-null  float64\n",
      " 16  CONCINDEX2         15030 non-null  int64  \n",
      " 17  CONC2              15030 non-null  float64\n",
      " 18  CONCUNIT2          15030 non-null  object \n",
      " 19  PERCENTGROWTH      15030 non-null  float64\n",
      " 20  PERCENTGROWTHNOTZ  15030 non-null  float64\n",
      " 21  TESTVALUE          15030 non-null  float64\n",
      " 22  CONTROLVALUE       15030 non-null  float64\n",
      " 23  TZVALUE            15030 non-null  float64\n",
      " 24  EXPECTEDGROWTH     15030 non-null  float64\n",
      " 25  SCORE              15030 non-null  float64\n",
      " 26  VALID              15030 non-null  object \n",
      " 27  PANEL              15030 non-null  object \n",
      " 28  CELLNAME           15030 non-null  object \n",
      " 29  PANELACRONYM       15030 non-null  object \n",
      " 30  CELLLINENAME       15030 non-null  object \n",
      "dtypes: float64(11), int64(7), object(13)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Drop na values\n",
    "data = data.dropna()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b813e81-e2a0-4b7d-a333-051c2c9f8df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available. TensorFlow is running on CPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"GPU is available and being used.\")\n",
    "else:\n",
    "    print(\"GPU is not available. TensorFlow is running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154ab41a-8d3d-4572-b597-d2bcc7e15544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Get visible devices (including GPUs)\n",
    "# visible_devices = tf.config.experimental.get_visible_devices()\n",
    "# print(\"Visible devices:\", visible_devices)\n",
    "\n",
    "# # Get memory info for each visible device\n",
    "# for device in visible_devices:\n",
    "#     if device.device_type == 'GPU':\n",
    "#         memory_info = tf.config.experimental.get_memory_info(device)\n",
    "#         print(\"Memory info for\", device.name, \":\", memory_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0c85f74-08a9-4586-8ee6-e4d837450503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 12024, X_test: 3006, y_train: 12024, y_test: 3006\n",
      "Fold 1, X_train_fold_scaled: 9619, X_valid_fold_scaled: 2405, X_test_scaled: 3006\n",
      "76/76 [==============================] - 0s 802us/step\n",
      "94/94 [==============================] - 0s 791us/step\n",
      "Fold 2, X_train_fold_scaled: 9619, X_valid_fold_scaled: 2405, X_test_scaled: 3006\n",
      "76/76 [==============================] - 0s 803us/step\n",
      "94/94 [==============================] - 0s 782us/step\n",
      "Fold 3, X_train_fold_scaled: 9619, X_valid_fold_scaled: 2405, X_test_scaled: 3006\n",
      "76/76 [==============================] - 0s 798us/step\n",
      "94/94 [==============================] - 0s 778us/step\n",
      "Fold 4, X_train_fold_scaled: 9619, X_valid_fold_scaled: 2405, X_test_scaled: 3006\n",
      "76/76 [==============================] - 0s 799us/step\n",
      "94/94 [==============================] - 0s 778us/step\n",
      "Fold 5, X_train_fold_scaled: 9620, X_valid_fold_scaled: 2404, X_test_scaled: 3006\n",
      "76/76 [==============================] - 0s 796us/step\n",
      "94/94 [==============================] - 0s 781us/step\n",
      "Mean AUC on test set: 0.7987452605873658\n",
      "Standard Deviation of AUC on test set: 0.015027542116259531\n",
      "AUCs on validation set for each fold: [0.8089161796932067, 0.8455673198482934, 0.8406150181365384, 0.8854638337396957, 0.84126649817467]\n"
     ]
    }
   ],
   "source": [
    "##### FNN classification model with 5-fold cross validations (TensorFlow)\n",
    "### (Code for individual sample)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Custom function to transform y\n",
    "def transform_labels(y):\n",
    "    return np.where(y <= 0, 0, 1)\n",
    "\n",
    "# Preprocess the data\n",
    "X = data[['NSC1', 'NSC2', 'CONC1', 'CONC2']].values\n",
    "y = data['PERCENTGROWTH'].values\n",
    "\n",
    "# Transform labels\n",
    "y = transform_labels(y)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f'X_train: {len(X_train)}, X_test: {len(X_test)}, y_train: {len(y_train)}, y_test: {len(y_test)}')\n",
    "\n",
    "# Define a function to build and evaluate the model\n",
    "def build_and_evaluate_model(X_train_fold, X_valid_fold, y_train_fold, y_valid_fold, X_test, y_test):\n",
    "    # Build the Feedforward Neural Network (FNN) model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_fold.shape[1],)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "    ])\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "    # Train the model\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=50, batch_size=32, verbose=0)\n",
    "    # Evaluate the model on the validation set\n",
    "    predictions = model.predict(X_valid_fold)\n",
    "    auc_valid = roc_auc_score(y_valid_fold, predictions)\n",
    "    # Evaluate the model on the test set\n",
    "    predictions_test = model.predict(X_test)\n",
    "    auc_test = roc_auc_score(y_test, predictions_test)\n",
    "    return auc_valid, auc_test\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store AUC scores for each fold\n",
    "auc_per_fold = []\n",
    "auc_test_per_fold = []\n",
    "\n",
    "# Loop through the folds\n",
    "i = 0\n",
    "for train_index, valid_index in kf.split(X_train):\n",
    "    X_train_fold, X_valid_fold = X_train[train_index], X_train[valid_index]\n",
    "    y_train_fold, y_valid_fold = y_train[train_index], y_train[valid_index]\n",
    "    # Standardize the input features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "    X_valid_fold_scaled = scaler.transform(X_valid_fold)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    i += 1\n",
    "    print(f'Fold {i}, X_train_fold_scaled: {len(X_train_fold_scaled)}, X_valid_fold_scaled: {len(X_valid_fold_scaled)}, X_test_scaled: {len(X_test_scaled)}')\n",
    "    # Evaluate the model for the current fold\n",
    "    auc_valid, auc_test = build_and_evaluate_model(X_train_fold_scaled, X_valid_fold_scaled, y_train_fold, y_valid_fold, X_test_scaled, y_test)\n",
    "    auc_per_fold.append(auc_valid)\n",
    "    auc_test_per_fold.append(auc_test)\n",
    "\n",
    "# Calculate mean and standard deviation of AUC scores\n",
    "mean_auc = np.mean(auc_test_per_fold)\n",
    "std_auc = np.std(auc_test_per_fold)\n",
    "\n",
    "print(f'Mean AUC on test set: {mean_auc}')\n",
    "print(f'Standard Deviation of AUC on test set: {std_auc}')\n",
    "print(f'AUCs on validation set for each fold: {auc_per_fold}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "125d2089-242a-4816-9262-6c22f08870bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FNN classification model with 5-fold cross validations (TensorFlow)\n",
    "### (Code for all)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Custom function to transform y\n",
    "def transform_labels(y):\n",
    "    return np.where(y <= 0, 0, 1)\n",
    "\n",
    "# Function to preprocess data, train the model, and evaluate\n",
    "def preprocess_train_evaluate(X_train_fold, X_valid_fold, y_train_fold, y_valid_fold, X_test, y_test):\n",
    "    # Build the Feedforward Neural Network (FNN) model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "    ])\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "    # Train the model\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=50, batch_size=32, verbose=0)\n",
    "    # Evaluate the model on the validation set\n",
    "    predictions = model.predict(X_valid_fold)\n",
    "    auc_valid = roc_auc_score(y_valid_fold, predictions)\n",
    "    # Evaluate the model on the test set\n",
    "    predictions_test = model.predict(X_test)\n",
    "    auc_test = roc_auc_score(y_test, predictions_test)\n",
    "    return auc_valid, auc_test\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each cell line\n",
    "for cell_line in combo_druggrowth_df['CELLLINENAME'].unique():\n",
    "    # Extract subset for the current cell line\n",
    "    subset = combo_druggrowth_df[combo_druggrowth_df['CELLLINENAME'] == cell_line]   \n",
    "    # Drop na values\n",
    "    subset = subset.dropna()   \n",
    "    # Extract features and target\n",
    "    X = subset[['NSC1', 'NSC2', 'CONC1', 'CONC2']].values\n",
    "    y = subset['PERCENTGROWTH'].values   \n",
    "    # Transform labels\n",
    "    y = transform_labels(y)\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    # Initialize lists to store AUC scores for each fold\n",
    "    auc_per_fold = []\n",
    "    auc_test_per_fold = []\n",
    "    # Loop through the folds\n",
    "    for train_index, valid_index in kf.split(X_train):\n",
    "        X_train_fold, X_valid_fold = X_train[train_index], X_train[valid_index]\n",
    "        y_train_fold, y_valid_fold = y_train[train_index], y_train[valid_index]\n",
    "        # Standardize the input features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_valid_fold_scaled = scaler.transform(X_valid_fold)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        # Evaluate the model for the current fold\n",
    "        auc_valid, auc_test = preprocess_train_evaluate(X_train_fold_scaled, X_valid_fold_scaled, y_train_fold, y_valid_fold, X_test_scaled, y_test)\n",
    "        auc_per_fold.append(auc_valid)\n",
    "        auc_test_per_fold.append(auc_test)\n",
    "    # Calculate mean and standard deviation of AUC scores\n",
    "    mean_auc = np.mean(auc_test_per_fold)\n",
    "    std_auc = np.std(auc_test_per_fold)\n",
    "    # Store results in a dictionary\n",
    "    result = {'CellLine': cell_line,\n",
    "              'Mean_AUC': mean_auc,\n",
    "              'Std_AUC': std_auc}    \n",
    "    # Append result to the list\n",
    "    results.append(result)\n",
    "\n",
    "# Convert list of dictionaries to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to a CSV file\n",
    "results_df.to_csv('auc_results_TensorFlow.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "818ec941-1276-4f84-a9ba-c6d3b2a56e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "results_df = pd.read_csv('auc_results_TensorFlow.csv')\n",
    "\n",
    "# Round the 'Mean_RMSE' and 'Std_RMSE' columns to two decimals\n",
    "results_df['Mean_AUC'] = results_df['Mean_AUC'].round(2)\n",
    "results_df['Std_AUC'] = results_df['Std_AUC'].round(4)\n",
    "\n",
    "results_df.to_csv('rounded_auc_results_TensorFlow.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fb4b658-e628-4037-83e9-2a2a247e3e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, X_train_fold_scaled: 9619, X_valid_fold_scaled: 2405, X_test_scaled: 3006\n",
      "76/76 [==============================] - 0s 791us/step\n",
      "94/94 [==============================] - 0s 770us/step\n",
      "Fold 2, X_train_fold_scaled: 9619, X_valid_fold_scaled: 2405, X_test_scaled: 3006\n",
      "76/76 [==============================] - 0s 785us/step\n",
      "94/94 [==============================] - 0s 771us/step\n",
      "Fold 3, X_train_fold_scaled: 9619, X_valid_fold_scaled: 2405, X_test_scaled: 3006\n",
      "76/76 [==============================] - 0s 791us/step\n",
      "94/94 [==============================] - 0s 762us/step\n",
      "Fold 4, X_train_fold_scaled: 9619, X_valid_fold_scaled: 2405, X_test_scaled: 3006\n",
      "76/76 [==============================] - 0s 781us/step\n",
      "94/94 [==============================] - 0s 772us/step\n",
      "Fold 5, X_train_fold_scaled: 9620, X_valid_fold_scaled: 2404, X_test_scaled: 3006\n",
      "76/76 [==============================] - 0s 781us/step\n",
      "94/94 [==============================] - 0s 766us/step\n",
      "Mean RMSE on test set: 27.345172972363507\n",
      "Standard Deviation of RMSE on test set: 0.1512767193176091\n",
      "RMSEs on validation set for each fold: [28.046833964532816, 27.541597551176288, 27.60643577929866, 27.5780700160982, 27.518604518491795]\n"
     ]
    }
   ],
   "source": [
    "##### FNN regression model with 5-fold cross validations (TensorFlow)\n",
    "### (Code for individual sample)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Preprocess the data\n",
    "X = data[['NSC1', 'NSC2', 'CONC1', 'CONC2']].values\n",
    "y = data['PERCENTGROWTH'].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a function to build and evaluate the model\n",
    "def build_and_evaluate_model(X_train_fold, X_valid_fold, y_train_fold, y_valid_fold, X_test, y_test):\n",
    "    # Build the Feedforward Neural Network (FNN) model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_fold.shape[1],)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)  # Output layer without activation for regression\n",
    "    ])\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
    "    # Train the model\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=50, batch_size=32, verbose=0)\n",
    "    # Evaluate the model on the validation set\n",
    "    predictions_valid = model.predict(X_valid_fold)\n",
    "    rmse_valid = np.sqrt(mean_squared_error(y_valid_fold, predictions_valid))\n",
    "    # Evaluate the model on the test set\n",
    "    predictions_test = model.predict(X_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, predictions_test))\n",
    "    return rmse_valid, rmse_test\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store RMSE scores for each fold\n",
    "rmse_per_fold = []\n",
    "rmse_test_per_fold = []\n",
    "\n",
    "# Loop through the folds\n",
    "i = 0\n",
    "for train_index, valid_index in kf.split(X_train):\n",
    "    X_train_fold, X_valid_fold = X_train[train_index], X_train[valid_index]\n",
    "    y_train_fold, y_valid_fold = y_train[train_index], y_train[valid_index]\n",
    "    # Standardize the input features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "    X_valid_fold_scaled = scaler.transform(X_valid_fold)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    i += 1\n",
    "    print(f'Fold {i}, X_train_fold_scaled: {len(X_train_fold_scaled)}, X_valid_fold_scaled: {len(X_valid_fold_scaled)}, X_test_scaled: {len(X_test_scaled)}')\n",
    "    # Evaluate the model for the current fold\n",
    "    rmse_valid, rmse_test = build_and_evaluate_model(X_train_fold_scaled, X_valid_fold_scaled, y_train_fold, y_valid_fold, X_test_scaled, y_test)\n",
    "    rmse_per_fold.append(rmse_valid)\n",
    "    rmse_test_per_fold.append(rmse_test)\n",
    "\n",
    "# Calculate mean and standard deviation of AUC scores\n",
    "mean_rmse = np.mean(rmse_test_per_fold)\n",
    "std_rmse = np.std(rmse_test_per_fold)\n",
    "\n",
    "print(f'Mean RMSE on test set: {mean_rmse}')\n",
    "print(f'Standard Deviation of RMSE on test set: {std_rmse}')\n",
    "print(f'RMSEs on validation set for each fold: {rmse_per_fold}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b95015c9-0986-436e-aca3-46a703e069bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 769us/step\n",
      "76/76 [==============================] - 0s 779us/step\n",
      "61/61 [==============================] - 0s 769us/step\n",
      "76/76 [==============================] - 0s 787us/step\n",
      "61/61 [==============================] - 0s 767us/step\n",
      "76/76 [==============================] - 0s 781us/step\n",
      "61/61 [==============================] - 0s 770us/step\n",
      "76/76 [==============================] - 0s 781us/step\n",
      "61/61 [==============================] - 0s 768us/step\n",
      "76/76 [==============================] - 0s 779us/step\n",
      "74/74 [==============================] - 0s 793us/step\n",
      "92/92 [==============================] - 0s 772us/step\n",
      "74/74 [==============================] - 0s 790us/step\n",
      "92/92 [==============================] - 0s 770us/step\n",
      "74/74 [==============================] - 0s 784us/step\n",
      "92/92 [==============================] - 0s 775us/step\n",
      "74/74 [==============================] - 0s 829us/step\n",
      "92/92 [==============================] - 0s 778us/step\n",
      "74/74 [==============================] - 0s 787us/step\n",
      "92/92 [==============================] - 0s 771us/step\n",
      "66/66 [==============================] - 0s 768us/step\n",
      "83/83 [==============================] - 0s 782us/step\n",
      "66/66 [==============================] - 0s 766us/step\n",
      "83/83 [==============================] - 0s 782us/step\n",
      "66/66 [==============================] - 0s 763us/step\n",
      "83/83 [==============================] - 0s 778us/step\n",
      "66/66 [==============================] - 0s 935us/step\n",
      "83/83 [==============================] - 0s 777us/step\n",
      "66/66 [==============================] - 0s 762us/step\n",
      "83/83 [==============================] - 0s 778us/step\n",
      "55/55 [==============================] - 0s 780us/step\n",
      "68/68 [==============================] - 0s 795us/step\n",
      "55/55 [==============================] - 0s 772us/step\n",
      "68/68 [==============================] - 0s 792us/step\n",
      "55/55 [==============================] - 0s 783us/step\n",
      "68/68 [==============================] - 0s 786us/step\n",
      "55/55 [==============================] - 0s 773us/step\n",
      "68/68 [==============================] - 0s 792us/step\n",
      "55/55 [==============================] - 0s 780us/step\n",
      "68/68 [==============================] - 0s 790us/step\n",
      "67/67 [==============================] - 0s 801us/step\n",
      "84/84 [==============================] - 0s 777us/step\n",
      "67/67 [==============================] - 0s 796us/step\n",
      "84/84 [==============================] - 0s 781us/step\n",
      "67/67 [==============================] - 0s 793us/step\n",
      "84/84 [==============================] - 0s 782us/step\n",
      "67/67 [==============================] - 0s 798us/step\n",
      "84/84 [==============================] - 0s 784us/step\n",
      "67/67 [==============================] - 0s 799us/step\n",
      "84/84 [==============================] - 0s 780us/step\n",
      "66/66 [==============================] - 0s 806us/step\n",
      "82/82 [==============================] - 0s 776us/step\n",
      "66/66 [==============================] - 0s 761us/step\n",
      "82/82 [==============================] - 0s 779us/step\n",
      "66/66 [==============================] - 0s 761us/step\n",
      "82/82 [==============================] - 0s 779us/step\n",
      "66/66 [==============================] - 0s 770us/step\n",
      "82/82 [==============================] - 0s 788us/step\n",
      "66/66 [==============================] - 0s 762us/step\n",
      "82/82 [==============================] - 0s 782us/step\n",
      "64/64 [==============================] - 0s 780us/step\n",
      "80/80 [==============================] - 0s 790us/step\n",
      "64/64 [==============================] - 0s 769us/step\n",
      "80/80 [==============================] - 0s 781us/step\n",
      "64/64 [==============================] - 0s 770us/step\n",
      "80/80 [==============================] - 0s 783us/step\n",
      "64/64 [==============================] - 0s 767us/step\n",
      "80/80 [==============================] - 0s 781us/step\n",
      "64/64 [==============================] - 0s 768us/step\n",
      "80/80 [==============================] - 0s 782us/step\n",
      "53/53 [==============================] - 0s 784us/step\n",
      "66/66 [==============================] - 0s 755us/step\n",
      "53/53 [==============================] - 0s 780us/step\n",
      "66/66 [==============================] - 0s 759us/step\n",
      "53/53 [==============================] - 0s 776us/step\n",
      "66/66 [==============================] - 0s 753us/step\n",
      "53/53 [==============================] - 0s 776us/step\n",
      "66/66 [==============================] - 0s 757us/step\n",
      "53/53 [==============================] - 0s 779us/step\n",
      "66/66 [==============================] - 0s 759us/step\n",
      "73/73 [==============================] - 0s 789us/step\n",
      "91/91 [==============================] - 0s 773us/step\n",
      "73/73 [==============================] - 0s 786us/step\n",
      "91/91 [==============================] - 0s 776us/step\n",
      "73/73 [==============================] - 0s 792us/step\n",
      "91/91 [==============================] - 0s 775us/step\n",
      "73/73 [==============================] - 0s 792us/step\n",
      "91/91 [==============================] - 0s 772us/step\n",
      "73/73 [==============================] - 0s 788us/step\n",
      "91/91 [==============================] - 0s 771us/step\n",
      "52/52 [==============================] - 0s 776us/step\n",
      "64/64 [==============================] - 0s 759us/step\n",
      "52/52 [==============================] - 0s 774us/step\n",
      "64/64 [==============================] - 0s 757us/step\n",
      "52/52 [==============================] - 0s 776us/step\n",
      "64/64 [==============================] - 0s 766us/step\n",
      "52/52 [==============================] - 0s 788us/step\n",
      "64/64 [==============================] - 0s 757us/step\n",
      "52/52 [==============================] - 0s 778us/step\n",
      "64/64 [==============================] - 0s 764us/step\n",
      "66/66 [==============================] - 0s 805us/step\n",
      "82/82 [==============================] - 0s 779us/step\n",
      "66/66 [==============================] - 0s 806us/step\n",
      "82/82 [==============================] - 0s 781us/step\n",
      "66/66 [==============================] - 0s 764us/step\n",
      "82/82 [==============================] - 0s 790us/step\n",
      "66/66 [==============================] - 0s 763us/step\n",
      "82/82 [==============================] - 0s 783us/step\n",
      "66/66 [==============================] - 0s 765us/step\n",
      "82/82 [==============================] - 0s 777us/step\n",
      "50/50 [==============================] - 0s 791us/step\n",
      "62/62 [==============================] - 0s 767us/step\n",
      "50/50 [==============================] - 0s 787us/step\n",
      "62/62 [==============================] - 0s 767us/step\n",
      "50/50 [==============================] - 0s 776us/step\n",
      "62/62 [==============================] - 0s 766us/step\n",
      "50/50 [==============================] - 0s 782us/step\n",
      "62/62 [==============================] - 0s 769us/step\n",
      "50/50 [==============================] - 0s 786us/step\n",
      "62/62 [==============================] - 0s 771us/step\n",
      "48/48 [==============================] - 0s 782us/step\n",
      "59/59 [==============================] - 0s 762us/step\n",
      "48/48 [==============================] - 0s 781us/step\n",
      "59/59 [==============================] - 0s 769us/step\n",
      "48/48 [==============================] - 0s 782us/step\n",
      "59/59 [==============================] - 0s 766us/step\n",
      "48/48 [==============================] - 0s 791us/step\n",
      "59/59 [==============================] - 0s 770us/step\n",
      "48/48 [==============================] - 0s 782us/step\n",
      "59/59 [==============================] - 0s 769us/step\n",
      "55/55 [==============================] - 0s 772us/step\n",
      "68/68 [==============================] - 0s 794us/step\n",
      "55/55 [==============================] - 0s 778us/step\n",
      "68/68 [==============================] - 0s 785us/step\n",
      "55/55 [==============================] - 0s 777us/step\n",
      "68/68 [==============================] - 0s 786us/step\n",
      "55/55 [==============================] - 0s 770us/step\n",
      "68/68 [==============================] - 0s 787us/step\n",
      "55/55 [==============================] - 0s 775us/step\n",
      "68/68 [==============================] - 0s 789us/step\n",
      "66/66 [==============================] - 0s 767us/step\n",
      "82/82 [==============================] - 0s 778us/step\n",
      "66/66 [==============================] - 0s 764us/step\n",
      "82/82 [==============================] - 0s 787us/step\n",
      "66/66 [==============================] - 0s 761us/step\n",
      "82/82 [==============================] - 0s 776us/step\n",
      "66/66 [==============================] - 0s 763us/step\n",
      "82/82 [==============================] - 0s 783us/step\n",
      "66/66 [==============================] - 0s 805us/step\n",
      "82/82 [==============================] - 0s 781us/step\n",
      "66/66 [==============================] - 0s 766us/step\n",
      "83/83 [==============================] - 0s 778us/step\n",
      "66/66 [==============================] - 0s 765us/step\n",
      "83/83 [==============================] - 0s 776us/step\n",
      "66/66 [==============================] - 0s 767us/step\n",
      "83/83 [==============================] - 0s 778us/step\n",
      "66/66 [==============================] - 0s 763us/step\n",
      "83/83 [==============================] - 0s 788us/step\n",
      "66/66 [==============================] - 0s 805us/step\n",
      "83/83 [==============================] - 0s 780us/step\n",
      "73/73 [==============================] - 0s 791us/step\n",
      "91/91 [==============================] - 0s 773us/step\n",
      "73/73 [==============================] - 0s 791us/step\n",
      "91/91 [==============================] - 0s 772us/step\n",
      "73/73 [==============================] - 0s 787us/step\n",
      "91/91 [==============================] - 0s 775us/step\n",
      "73/73 [==============================] - 0s 794us/step\n",
      "91/91 [==============================] - 0s 773us/step\n",
      "73/73 [==============================] - 0s 790us/step\n",
      "91/91 [==============================] - 0s 777us/step\n",
      "75/75 [==============================] - 0s 797us/step\n",
      "94/94 [==============================] - 0s 800us/step\n",
      "75/75 [==============================] - 0s 796us/step\n",
      "94/94 [==============================] - 0s 779us/step\n",
      "75/75 [==============================] - 0s 807us/step\n",
      "94/94 [==============================] - 0s 778us/step\n",
      "75/75 [==============================] - 0s 787us/step\n",
      "94/94 [==============================] - 0s 811us/step\n",
      "75/75 [==============================] - 0s 791us/step\n",
      "94/94 [==============================] - 0s 774us/step\n",
      "73/73 [==============================] - 0s 806us/step\n",
      "91/91 [==============================] - 0s 783us/step\n",
      "73/73 [==============================] - 0s 795us/step\n",
      "91/91 [==============================] - 0s 778us/step\n",
      "73/73 [==============================] - 0s 794us/step\n",
      "91/91 [==============================] - 0s 773us/step\n",
      "73/73 [==============================] - 0s 791us/step\n",
      "91/91 [==============================] - 0s 776us/step\n",
      "73/73 [==============================] - 0s 792us/step\n",
      "91/91 [==============================] - 0s 772us/step\n",
      "58/58 [==============================] - 0s 771us/step\n",
      "72/72 [==============================] - 0s 787us/step\n",
      "58/58 [==============================] - 0s 781us/step\n",
      "72/72 [==============================] - 0s 789us/step\n",
      "58/58 [==============================] - 0s 775us/step\n",
      "72/72 [==============================] - 0s 783us/step\n",
      "58/58 [==============================] - 0s 771us/step\n",
      "72/72 [==============================] - 0s 792us/step\n",
      "58/58 [==============================] - 0s 772us/step\n",
      "72/72 [==============================] - 0s 787us/step\n",
      "68/68 [==============================] - 0s 799us/step\n",
      "84/84 [==============================] - 0s 782us/step\n",
      "68/68 [==============================] - 0s 792us/step\n",
      "84/84 [==============================] - 0s 782us/step\n",
      "68/68 [==============================] - 0s 801us/step\n",
      "84/84 [==============================] - 0s 782us/step\n",
      "68/68 [==============================] - 0s 795us/step\n",
      "84/84 [==============================] - 0s 781us/step\n",
      "68/68 [==============================] - 0s 799us/step\n",
      "84/84 [==============================] - 0s 777us/step\n",
      "60/60 [==============================] - 0s 768us/step\n",
      "75/75 [==============================] - 0s 791us/step\n",
      "60/60 [==============================] - 0s 778us/step\n",
      "75/75 [==============================] - 0s 790us/step\n",
      "60/60 [==============================] - 0s 766us/step\n",
      "75/75 [==============================] - 0s 793us/step\n",
      "60/60 [==============================] - 0s 775us/step\n",
      "75/75 [==============================] - 0s 779us/step\n",
      "60/60 [==============================] - 0s 769us/step\n",
      "75/75 [==============================] - 0s 788us/step\n",
      "76/76 [==============================] - 0s 784us/step\n",
      "94/94 [==============================] - 0s 771us/step\n",
      "76/76 [==============================] - 0s 795us/step\n",
      "94/94 [==============================] - 0s 775us/step\n",
      "76/76 [==============================] - 0s 785us/step\n",
      "94/94 [==============================] - 0s 774us/step\n",
      "76/76 [==============================] - 0s 794us/step\n",
      "94/94 [==============================] - 0s 775us/step\n",
      "76/76 [==============================] - 0s 786us/step\n",
      "94/94 [==============================] - 0s 770us/step\n",
      "55/55 [==============================] - 0s 770us/step\n",
      "68/68 [==============================] - 0s 790us/step\n",
      "55/55 [==============================] - 0s 772us/step\n",
      "68/68 [==============================] - 0s 791us/step\n",
      "55/55 [==============================] - 0s 777us/step\n",
      "68/68 [==============================] - 0s 794us/step\n",
      "55/55 [==============================] - 0s 773us/step\n",
      "68/68 [==============================] - 0s 795us/step\n",
      "55/55 [==============================] - 0s 787us/step\n",
      "68/68 [==============================] - 0s 801us/step\n",
      "71/71 [==============================] - 0s 800us/step\n",
      "89/89 [==============================] - 0s 781us/step\n",
      "71/71 [==============================] - 0s 800us/step\n",
      "89/89 [==============================] - 0s 790us/step\n",
      "71/71 [==============================] - 0s 793us/step\n",
      "89/89 [==============================] - 0s 786us/step\n",
      "71/71 [==============================] - 0s 798us/step\n",
      "89/89 [==============================] - 0s 782us/step\n",
      "71/71 [==============================] - 0s 798us/step\n",
      "89/89 [==============================] - 0s 778us/step\n",
      "73/73 [==============================] - 0s 797us/step\n",
      "92/92 [==============================] - 0s 778us/step\n",
      "73/73 [==============================] - 0s 802us/step\n",
      "92/92 [==============================] - 0s 775us/step\n",
      "73/73 [==============================] - 0s 793us/step\n",
      "92/92 [==============================] - 0s 774us/step\n",
      "73/73 [==============================] - 0s 791us/step\n",
      "92/92 [==============================] - 0s 781us/step\n",
      "73/73 [==============================] - 0s 797us/step\n",
      "92/92 [==============================] - 0s 777us/step\n",
      "66/66 [==============================] - 0s 767us/step\n",
      "83/83 [==============================] - 0s 780us/step\n",
      "66/66 [==============================] - 0s 769us/step\n",
      "83/83 [==============================] - 0s 783us/step\n",
      "66/66 [==============================] - 0s 769us/step\n",
      "83/83 [==============================] - 0s 777us/step\n",
      "66/66 [==============================] - 0s 761us/step\n",
      "83/83 [==============================] - 0s 780us/step\n",
      "66/66 [==============================] - 0s 764us/step\n",
      "83/83 [==============================] - 0s 792us/step\n",
      "55/55 [==============================] - 0s 777us/step\n",
      "69/69 [==============================] - 0s 789us/step\n",
      "55/55 [==============================] - 0s 773us/step\n",
      "69/69 [==============================] - 0s 788us/step\n",
      "55/55 [==============================] - 0s 779us/step\n",
      "69/69 [==============================] - 0s 788us/step\n",
      "55/55 [==============================] - 0s 774us/step\n",
      "69/69 [==============================] - 0s 789us/step\n",
      "55/55 [==============================] - 0s 784us/step\n",
      "69/69 [==============================] - 0s 789us/step\n",
      "49/49 [==============================] - 0s 776us/step\n",
      "62/62 [==============================] - 0s 771us/step\n",
      "49/49 [==============================] - 0s 782us/step\n",
      "62/62 [==============================] - 0s 759us/step\n",
      "49/49 [==============================] - 0s 777us/step\n",
      "62/62 [==============================] - 0s 763us/step\n",
      "49/49 [==============================] - 0s 776us/step\n",
      "62/62 [==============================] - 0s 762us/step\n",
      "49/49 [==============================] - 0s 779us/step\n",
      "62/62 [==============================] - 0s 765us/step\n",
      "73/73 [==============================] - 0s 793us/step\n",
      "91/91 [==============================] - 0s 768us/step\n",
      "73/73 [==============================] - 0s 790us/step\n",
      "91/91 [==============================] - 0s 769us/step\n",
      "73/73 [==============================] - 0s 787us/step\n",
      "91/91 [==============================] - 0s 774us/step\n",
      "73/73 [==============================] - 0s 792us/step\n",
      "91/91 [==============================] - 0s 777us/step\n",
      "73/73 [==============================] - 0s 790us/step\n",
      "91/91 [==============================] - 0s 778us/step\n",
      "73/73 [==============================] - 0s 802us/step\n",
      "91/91 [==============================] - 0s 777us/step\n",
      "73/73 [==============================] - 0s 797us/step\n",
      "91/91 [==============================] - 0s 773us/step\n",
      "73/73 [==============================] - 0s 792us/step\n",
      "91/91 [==============================] - 0s 773us/step\n",
      "73/73 [==============================] - 0s 788us/step\n",
      "91/91 [==============================] - 0s 773us/step\n",
      "73/73 [==============================] - 0s 795us/step\n",
      "91/91 [==============================] - 0s 780us/step\n",
      "54/54 [==============================] - 0s 774us/step\n",
      "67/67 [==============================] - 0s 794us/step\n",
      "54/54 [==============================] - 0s 785us/step\n",
      "67/67 [==============================] - 0s 794us/step\n",
      "54/54 [==============================] - 0s 769us/step\n",
      "67/67 [==============================] - 0s 756us/step\n",
      "54/54 [==============================] - 0s 774us/step\n",
      "67/67 [==============================] - 0s 793us/step\n",
      "54/54 [==============================] - 0s 780us/step\n",
      "67/67 [==============================] - 0s 803us/step\n",
      "70/70 [==============================] - 0s 810us/step\n",
      "88/88 [==============================] - 0s 787us/step\n",
      "70/70 [==============================] - 0s 805us/step\n",
      "88/88 [==============================] - 0s 788us/step\n",
      "70/70 [==============================] - 0s 799us/step\n",
      "88/88 [==============================] - 0s 793us/step\n",
      "70/70 [==============================] - 0s 810us/step\n",
      "88/88 [==============================] - 0s 789us/step\n",
      "70/70 [==============================] - 0s 804us/step\n",
      "88/88 [==============================] - 0s 791us/step\n",
      "61/61 [==============================] - 0s 775us/step\n",
      "76/76 [==============================] - 0s 788us/step\n",
      "61/61 [==============================] - 0s 773us/step\n",
      "76/76 [==============================] - 0s 791us/step\n",
      "61/61 [==============================] - 0s 773us/step\n",
      "76/76 [==============================] - 0s 792us/step\n",
      "61/61 [==============================] - 0s 784us/step\n",
      "76/76 [==============================] - 0s 795us/step\n",
      "61/61 [==============================] - 0s 776us/step\n",
      "76/76 [==============================] - 0s 783us/step\n",
      "58/58 [==============================] - 0s 770us/step\n",
      "73/73 [==============================] - 0s 803us/step\n",
      "58/58 [==============================] - 0s 768us/step\n",
      "73/73 [==============================] - 0s 784us/step\n",
      "58/58 [==============================] - 0s 775us/step\n",
      "73/73 [==============================] - 0s 787us/step\n",
      "58/58 [==============================] - 0s 769us/step\n",
      "73/73 [==============================] - 0s 791us/step\n",
      "58/58 [==============================] - 0s 779us/step\n",
      "73/73 [==============================] - 0s 787us/step\n",
      "58/58 [==============================] - 0s 777us/step\n",
      "72/72 [==============================] - 0s 792us/step\n",
      "58/58 [==============================] - 0s 769us/step\n",
      "72/72 [==============================] - 0s 791us/step\n",
      "58/58 [==============================] - 0s 775us/step\n",
      "72/72 [==============================] - 0s 791us/step\n",
      "58/58 [==============================] - 0s 770us/step\n",
      "72/72 [==============================] - 0s 790us/step\n",
      "58/58 [==============================] - 0s 774us/step\n",
      "72/72 [==============================] - 0s 793us/step\n",
      "39/39 [==============================] - 0s 797us/step\n",
      "49/49 [==============================] - 0s 783us/step\n",
      "39/39 [==============================] - 0s 796us/step\n",
      "49/49 [==============================] - 0s 773us/step\n",
      "39/39 [==============================] - 0s 807us/step\n",
      "49/49 [==============================] - 0s 767us/step\n",
      "39/39 [==============================] - 0s 796us/step\n",
      "49/49 [==============================] - 0s 778us/step\n",
      "39/39 [==============================] - 0s 794us/step\n",
      "49/49 [==============================] - 0s 778us/step\n",
      "65/65 [==============================] - 0s 764us/step\n",
      "82/82 [==============================] - 0s 785us/step\n",
      "65/65 [==============================] - 0s 764us/step\n",
      "82/82 [==============================] - 0s 784us/step\n",
      "65/65 [==============================] - 0s 764us/step\n",
      "82/82 [==============================] - 0s 785us/step\n",
      "65/65 [==============================] - 0s 761us/step\n",
      "82/82 [==============================] - 0s 783us/step\n",
      "65/65 [==============================] - 0s 767us/step\n",
      "82/82 [==============================] - 0s 786us/step\n",
      "66/66 [==============================] - 0s 764us/step\n",
      "83/83 [==============================] - 0s 780us/step\n",
      "66/66 [==============================] - 0s 766us/step\n",
      "83/83 [==============================] - 0s 776us/step\n",
      "66/66 [==============================] - 0s 766us/step\n",
      "83/83 [==============================] - 0s 780us/step\n",
      "66/66 [==============================] - 0s 766us/step\n",
      "83/83 [==============================] - 0s 781us/step\n",
      "66/66 [==============================] - 0s 763us/step\n",
      "83/83 [==============================] - 0s 788us/step\n",
      "74/74 [==============================] - 0s 795us/step\n",
      "92/92 [==============================] - 0s 775us/step\n",
      "74/74 [==============================] - 0s 802us/step\n",
      "92/92 [==============================] - 0s 777us/step\n",
      "74/74 [==============================] - 0s 795us/step\n",
      "92/92 [==============================] - 0s 775us/step\n",
      "74/74 [==============================] - 0s 792us/step\n",
      "92/92 [==============================] - 0s 779us/step\n",
      "74/74 [==============================] - 0s 790us/step\n",
      "92/92 [==============================] - 0s 772us/step\n",
      "66/66 [==============================] - 0s 770us/step\n",
      "83/83 [==============================] - 0s 780us/step\n",
      "66/66 [==============================] - 0s 770us/step\n",
      "83/83 [==============================] - 0s 793us/step\n",
      "66/66 [==============================] - 0s 805us/step\n",
      "83/83 [==============================] - 0s 785us/step\n",
      "66/66 [==============================] - 0s 766us/step\n",
      "83/83 [==============================] - 0s 780us/step\n",
      "66/66 [==============================] - 0s 768us/step\n",
      "83/83 [==============================] - 0s 779us/step\n",
      "66/66 [==============================] - 0s 768us/step\n",
      "82/82 [==============================] - 0s 784us/step\n",
      "66/66 [==============================] - 0s 814us/step\n",
      "82/82 [==============================] - 0s 798us/step\n",
      "66/66 [==============================] - 0s 818us/step\n",
      "82/82 [==============================] - 0s 795us/step\n",
      "66/66 [==============================] - 0s 807us/step\n",
      "82/82 [==============================] - 0s 789us/step\n",
      "66/66 [==============================] - 0s 810us/step\n",
      "82/82 [==============================] - 0s 790us/step\n",
      "66/66 [==============================] - 0s 808us/step\n",
      "83/83 [==============================] - 0s 793us/step\n",
      "66/66 [==============================] - 0s 765us/step\n",
      "83/83 [==============================] - 0s 784us/step\n",
      "66/66 [==============================] - 0s 769us/step\n",
      "83/83 [==============================] - 0s 780us/step\n",
      "66/66 [==============================] - 0s 767us/step\n",
      "83/83 [==============================] - 0s 776us/step\n",
      "66/66 [==============================] - 0s 760us/step\n",
      "83/83 [==============================] - 0s 778us/step\n",
      "65/65 [==============================] - 0s 763us/step\n",
      "81/81 [==============================] - 0s 777us/step\n",
      "65/65 [==============================] - 0s 763us/step\n",
      "81/81 [==============================] - 0s 774us/step\n",
      "65/65 [==============================] - 0s 761us/step\n",
      "81/81 [==============================] - 0s 772us/step\n",
      "65/65 [==============================] - 0s 768us/step\n",
      "81/81 [==============================] - 0s 776us/step\n",
      "65/65 [==============================] - 0s 757us/step\n",
      "81/81 [==============================] - 0s 777us/step\n",
      "54/54 [==============================] - 0s 781us/step\n",
      "67/67 [==============================] - 0s 793us/step\n",
      "54/54 [==============================] - 0s 772us/step\n",
      "67/67 [==============================] - 0s 754us/step\n",
      "54/54 [==============================] - 0s 771us/step\n",
      "67/67 [==============================] - 0s 752us/step\n",
      "54/54 [==============================] - 0s 769us/step\n",
      "67/67 [==============================] - 0s 756us/step\n",
      "54/54 [==============================] - 0s 777us/step\n",
      "67/67 [==============================] - 0s 799us/step\n",
      "46/46 [==============================] - 0s 783us/step\n",
      "58/58 [==============================] - 0s 760us/step\n",
      "46/46 [==============================] - 0s 783us/step\n",
      "58/58 [==============================] - 0s 765us/step\n",
      "46/46 [==============================] - 0s 784us/step\n",
      "58/58 [==============================] - 0s 763us/step\n",
      "46/46 [==============================] - 0s 778us/step\n",
      "58/58 [==============================] - 0s 765us/step\n",
      "46/46 [==============================] - 0s 782us/step\n",
      "58/58 [==============================] - 0s 763us/step\n",
      "71/71 [==============================] - 0s 781us/step\n",
      "89/89 [==============================] - 0s 768us/step\n",
      "71/71 [==============================] - 0s 784us/step\n",
      "89/89 [==============================] - 0s 764us/step\n",
      "71/71 [==============================] - 0s 786us/step\n",
      "89/89 [==============================] - 0s 768us/step\n",
      "71/71 [==============================] - 0s 782us/step\n",
      "89/89 [==============================] - 0s 766us/step\n",
      "71/71 [==============================] - 0s 785us/step\n",
      "89/89 [==============================] - 0s 767us/step\n",
      "66/66 [==============================] - 0s 763us/step\n",
      "82/82 [==============================] - 0s 772us/step\n",
      "66/66 [==============================] - 0s 760us/step\n",
      "82/82 [==============================] - 0s 771us/step\n",
      "66/66 [==============================] - 0s 761us/step\n",
      "82/82 [==============================] - 0s 775us/step\n",
      "66/66 [==============================] - 0s 762us/step\n",
      "82/82 [==============================] - 0s 778us/step\n",
      "66/66 [==============================] - 0s 760us/step\n",
      "82/82 [==============================] - 0s 773us/step\n",
      "61/61 [==============================] - 0s 764us/step\n",
      "76/76 [==============================] - 0s 770us/step\n",
      "61/61 [==============================] - 0s 766us/step\n",
      "76/76 [==============================] - 0s 768us/step\n",
      "61/61 [==============================] - 0s 758us/step\n",
      "76/76 [==============================] - 0s 766us/step\n",
      "61/61 [==============================] - 0s 760us/step\n",
      "76/76 [==============================] - 0s 769us/step\n",
      "61/61 [==============================] - 0s 759us/step\n",
      "76/76 [==============================] - 0s 767us/step\n",
      "67/67 [==============================] - 0s 757us/step\n",
      "83/83 [==============================] - 0s 766us/step\n",
      "67/67 [==============================] - 0s 757us/step\n",
      "83/83 [==============================] - 0s 764us/step\n",
      "67/67 [==============================] - 0s 801us/step\n",
      "83/83 [==============================] - 0s 778us/step\n",
      "67/67 [==============================] - 0s 793us/step\n",
      "83/83 [==============================] - 0s 780us/step\n",
      "67/67 [==============================] - 0s 792us/step\n",
      "83/83 [==============================] - 0s 779us/step\n",
      "67/67 [==============================] - 0s 796us/step\n",
      "83/83 [==============================] - 0s 777us/step\n",
      "67/67 [==============================] - 0s 799us/step\n",
      "83/83 [==============================] - 0s 788us/step\n",
      "67/67 [==============================] - 0s 795us/step\n",
      "83/83 [==============================] - 0s 779us/step\n",
      "67/67 [==============================] - 0s 796us/step\n",
      "83/83 [==============================] - 0s 778us/step\n",
      "67/67 [==============================] - 0s 795us/step\n",
      "83/83 [==============================] - 0s 777us/step\n",
      "64/64 [==============================] - 0s 759us/step\n",
      "79/79 [==============================] - 0s 778us/step\n",
      "64/64 [==============================] - 0s 761us/step\n",
      "79/79 [==============================] - 0s 774us/step\n",
      "64/64 [==============================] - 0s 757us/step\n",
      "79/79 [==============================] - 0s 785us/step\n",
      "64/64 [==============================] - 0s 773us/step\n",
      "79/79 [==============================] - 0s 781us/step\n",
      "64/64 [==============================] - 0s 764us/step\n",
      "79/79 [==============================] - 0s 782us/step\n",
      "17/17 [==============================] - 0s 881us/step\n",
      "22/22 [==============================] - 0s 836us/step\n",
      "17/17 [==============================] - 0s 902us/step\n",
      "22/22 [==============================] - 0s 853us/step\n",
      "17/17 [==============================] - 0s 912us/step\n",
      "22/22 [==============================] - 0s 856us/step\n",
      "17/17 [==============================] - 0s 898us/step\n",
      "22/22 [==============================] - 0s 864us/step\n",
      "17/17 [==============================] - 0s 907us/step\n",
      "22/22 [==============================] - 0s 850us/step\n",
      "61/61 [==============================] - 0s 777us/step\n",
      "76/76 [==============================] - 0s 792us/step\n",
      "61/61 [==============================] - 0s 772us/step\n",
      "76/76 [==============================] - 0s 794us/step\n",
      "61/61 [==============================] - 0s 780us/step\n",
      "76/76 [==============================] - 0s 794us/step\n",
      "61/61 [==============================] - 0s 772us/step\n",
      "76/76 [==============================] - 0s 792us/step\n",
      "61/61 [==============================] - 0s 779us/step\n",
      "76/76 [==============================] - 0s 788us/step\n",
      "58/58 [==============================] - 0s 782us/step\n",
      "73/73 [==============================] - 0s 791us/step\n",
      "58/58 [==============================] - 0s 772us/step\n",
      "73/73 [==============================] - 0s 780us/step\n",
      "58/58 [==============================] - 0s 773us/step\n",
      "73/73 [==============================] - 0s 787us/step\n",
      "58/58 [==============================] - 0s 771us/step\n",
      "73/73 [==============================] - 0s 793us/step\n",
      "58/58 [==============================] - 0s 778us/step\n",
      "73/73 [==============================] - 0s 785us/step\n",
      "41/41 [==============================] - 0s 798us/step\n",
      "51/51 [==============================] - 0s 774us/step\n",
      "41/41 [==============================] - 0s 797us/step\n",
      "51/51 [==============================] - 0s 775us/step\n",
      "41/41 [==============================] - 0s 787us/step\n",
      "51/51 [==============================] - 0s 775us/step\n",
      "41/41 [==============================] - 0s 791us/step\n",
      "51/51 [==============================] - 0s 767us/step\n",
      "41/41 [==============================] - 0s 787us/step\n",
      "51/51 [==============================] - 0s 770us/step\n",
      "64/64 [==============================] - 0s 759us/step\n",
      "80/80 [==============================] - 0s 786us/step\n",
      "64/64 [==============================] - 0s 768us/step\n",
      "80/80 [==============================] - 0s 779us/step\n",
      "64/64 [==============================] - 0s 771us/step\n",
      "80/80 [==============================] - 0s 784us/step\n",
      "64/64 [==============================] - 0s 764us/step\n",
      "80/80 [==============================] - 0s 781us/step\n",
      "64/64 [==============================] - 0s 766us/step\n",
      "80/80 [==============================] - 0s 785us/step\n",
      "66/66 [==============================] - 0s 760us/step\n",
      "83/83 [==============================] - 0s 782us/step\n",
      "66/66 [==============================] - 0s 763us/step\n",
      "83/83 [==============================] - 0s 780us/step\n",
      "66/66 [==============================] - 0s 765us/step\n",
      "83/83 [==============================] - 0s 780us/step\n",
      "66/66 [==============================] - 0s 763us/step\n",
      "83/83 [==============================] - 0s 776us/step\n",
      "66/66 [==============================] - 0s 764us/step\n",
      "83/83 [==============================] - 0s 782us/step\n",
      "71/71 [==============================] - 0s 800us/step\n",
      "89/89 [==============================] - 0s 777us/step\n",
      "71/71 [==============================] - 0s 792us/step\n",
      "89/89 [==============================] - 0s 777us/step\n",
      "71/71 [==============================] - 0s 786us/step\n",
      "89/89 [==============================] - 0s 772us/step\n",
      "71/71 [==============================] - 0s 790us/step\n",
      "89/89 [==============================] - 0s 778us/step\n",
      "71/71 [==============================] - 0s 792us/step\n",
      "89/89 [==============================] - 0s 772us/step\n",
      "66/66 [==============================] - 0s 769us/step\n",
      "83/83 [==============================] - 0s 773us/step\n",
      "66/66 [==============================] - 0s 805us/step\n",
      "83/83 [==============================] - 0s 782us/step\n",
      "66/66 [==============================] - 0s 759us/step\n",
      "83/83 [==============================] - 0s 777us/step\n",
      "66/66 [==============================] - 0s 765us/step\n",
      "83/83 [==============================] - 0s 776us/step\n",
      "66/66 [==============================] - 0s 762us/step\n",
      "83/83 [==============================] - 0s 778us/step\n"
     ]
    }
   ],
   "source": [
    "##### FNN regression model with 5-fold cross validations (TensorFlow)\n",
    "### (Code for all)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Function to preprocess data, train the model, and evaluate\n",
    "def preprocess_train_evaluate(X_train_fold, X_valid_fold, y_train_fold, y_valid_fold, X_test, y_test):\n",
    "    # Build the Feedforward Neural Network (FNN) model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_fold.shape[1],)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)  # Output layer without activation for regression\n",
    "    ])\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
    "    # Train the model\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=50, batch_size=32, verbose=0)\n",
    "    # Evaluate the model on the validation set\n",
    "    predictions_valid = model.predict(X_valid_fold)\n",
    "    rmse_valid = np.sqrt(mean_squared_error(y_valid_fold, predictions_valid))\n",
    "    # Evaluate the model on the test set\n",
    "    predictions_test = model.predict(X_test)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, predictions_test))\n",
    "    return rmse_valid, rmse_test\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each cell line\n",
    "for cell_line in combo_druggrowth_df['CELLLINENAME'].unique():\n",
    "    # Extract subset for the current cell line\n",
    "    subset = combo_druggrowth_df[combo_druggrowth_df['CELLLINENAME'] == cell_line]    \n",
    "    # Drop na values\n",
    "    subset = subset.dropna()    \n",
    "    # Extract features and target\n",
    "    X = subset[['NSC1', 'NSC2', 'CONC1', 'CONC2']].values\n",
    "    y = subset['PERCENTGROWTH'].values  \n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    # Initialize lists to store RMSE scores for each fold\n",
    "    rmse_per_fold = []\n",
    "    rmse_test_per_fold = []\n",
    "    # Loop through the folds\n",
    "    for train_index, valid_index in kf.split(X_train):\n",
    "        X_train_fold, X_valid_fold = X_train[train_index], X_train[valid_index]\n",
    "        y_train_fold, y_valid_fold = y_train[train_index], y_train[valid_index]\n",
    "        # Standardize the input features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_valid_fold_scaled = scaler.transform(X_valid_fold)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        # Evaluate the model for the current fold\n",
    "        rmse_valid, rmse_test = preprocess_train_evaluate(X_train_fold_scaled, X_valid_fold_scaled, y_train_fold, y_valid_fold, X_test_scaled, y_test)\n",
    "        rmse_per_fold.append(rmse_valid)\n",
    "        rmse_test_per_fold.append(rmse_test)\n",
    "    # Calculate mean and standard deviation of AUC scores\n",
    "    mean_rmse = np.mean(rmse_test_per_fold)\n",
    "    std_rmse = np.std(rmse_test_per_fold)\n",
    "    # Store results in a dictionary\n",
    "    result = {'CellLine': cell_line,\n",
    "              'Mean_RMSE': mean_rmse,\n",
    "              'Std_RMSE': std_rmse}   \n",
    "    # Append result to the list\n",
    "    results.append(result)\n",
    "\n",
    "# Convert list of dictionaries to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to a CSV file\n",
    "results_df.to_csv('rmse_results_TensorFlow.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc5c5e75-e0b2-437b-a941-8c71bce283d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "results_df = pd.read_csv('rmse_results_TensorFlow.csv')\n",
    "\n",
    "# Round the 'Mean_RMSE' and 'Std_RMSE' columns to two decimals\n",
    "results_df['Mean_RMSE'] = results_df['Mean_RMSE'].round(2)\n",
    "results_df['Std_RMSE'] = results_df['Std_RMSE'].round(4)\n",
    "\n",
    "results_df.to_csv('rounded_rmse_results_TensorFlow.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d39b134-42f5-49de-8d16-6bb767ea439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FNN\n",
    "# ## (Code for individual sample)\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# # Custom function to transform y\n",
    "# def transform_labels(y):\n",
    "#     return np.where(y <= 0, 0, 1)\n",
    "\n",
    "# # Preprocess the data\n",
    "# X = data[['NSC1', 'NSC2', 'CONC1', 'CONC2']].values\n",
    "# y = data['PERCENTGROWTH'].values\n",
    "\n",
    "# # Transform labels\n",
    "# y = transform_labels(y)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Standardize the input features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # Build the Feedforward Neural Network (FNN) model\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "#     tf.keras.layers.Dense(32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# predictions = model.predict(X_test_scaled)\n",
    "# y_pred_labels = np.where(predictions <= 0.5, 0, 1)\n",
    "\n",
    "# # Compute evaluation metrics\n",
    "# accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "# precision = precision_score(y_test, y_pred_labels)\n",
    "# recall = recall_score(y_test, y_pred_labels)\n",
    "# f1 = f1_score(y_test, y_pred_labels)\n",
    "# auc = roc_auc_score(y_test, predictions)\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred_labels)\n",
    "\n",
    "# print(accuracy)\n",
    "# print(precision)\n",
    "# print(recall)\n",
    "# print(f1)\n",
    "# print(auc)\n",
    "# print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d8c2db2-5977-4b29-98d5-4aa7b23dbb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FNN\n",
    "# ## (Code for all)\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# # Custom function to transform y\n",
    "# def transform_labels(y):\n",
    "#     return np.where(y <= 0, 0, 1)\n",
    "\n",
    "# # Function to preprocess data, train the model, and evaluate\n",
    "# def preprocess_train_evaluate(X, y):\n",
    "#     # Transform labels\n",
    "#     y = transform_labels(y)\n",
    "\n",
    "#     # Split the data into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Standardize the input features\n",
    "#     scaler = StandardScaler()\n",
    "#     X_train_scaled = scaler.fit_transform(X_train)\n",
    "#     X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#     # Build the Feedforward Neural Network (FNN) model\n",
    "#     model = tf.keras.Sequential([\n",
    "#         tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "#         tf.keras.layers.Dense(32, activation='relu'),\n",
    "#         tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "#     ])\n",
    "\n",
    "#     # Compile the model\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "#     # Train the model\n",
    "#     model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=0)\n",
    "\n",
    "#     # Evaluate the model on the test set\n",
    "#     predictions = model.predict(X_test_scaled)\n",
    "#     y_pred_labels = np.where(predictions <= 0.5, 0, 1)\n",
    "\n",
    "#     # Compute evaluation metrics\n",
    "#     accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "#     precision = precision_score(y_test, y_pred_labels)\n",
    "#     recall = recall_score(y_test, y_pred_labels)\n",
    "#     f1 = f1_score(y_test, y_pred_labels)\n",
    "#     auc = roc_auc_score(y_test, predictions)\n",
    "#     conf_matrix = confusion_matrix(y_test, y_pred_labels)\n",
    "\n",
    "#     return accuracy, precision, recall, f1, auc, conf_matrix\n",
    "\n",
    "# # List to store results\n",
    "# results = []\n",
    "\n",
    "# # Loop through each cell line\n",
    "# for cell_line in combo_druggrowth_df['CELLLINENAME'].unique():\n",
    "#     # Extract subset for the current cell line\n",
    "#     subset = combo_druggrowth_df[combo_druggrowth_df['CELLLINENAME'] == cell_line]\n",
    "    \n",
    "#     # Drop na values\n",
    "#     subset = subset.dropna()\n",
    "    \n",
    "#     # Extract features and target\n",
    "#     X = subset[['NSC1', 'NSC2', 'CONC1', 'CONC2']].values\n",
    "#     y = subset['PERCENTGROWTH'].values\n",
    "    \n",
    "#     # Preprocess, train, and evaluate\n",
    "#     accuracy, precision, recall, f1, auc, _ = preprocess_train_evaluate(X, y)\n",
    "    \n",
    "#     # Store results in a dictionary\n",
    "#     result = {'CellLine': cell_line,\n",
    "#               'Accuracy': accuracy,\n",
    "#               'Precision': precision,\n",
    "#               'Recall': recall,\n",
    "#               'F1 Score': f1,\n",
    "#               'AUC': auc}\n",
    "    \n",
    "#     # Append result to the list\n",
    "#     results.append(result)\n",
    "\n",
    "# # Convert list of dictionaries to DataFrame\n",
    "# results_df = pd.DataFrame(results)\n",
    "\n",
    "# # Save results to a CSV file\n",
    "# results_df.to_csv('evaluation_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97568626-565d-45f9-8ffb-047dcab55e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
